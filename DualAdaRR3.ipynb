{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import math\n",
    "from metric import get_mrr, get_recall\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import pickle\n",
    "from entmax import entmax_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "test64 = pickle.load(open('data/retailrocket/test.txt', 'rb'))\n",
    "train64 = pickle.load(open('data/retailrocket/train.txt', 'rb'))\n",
    "\n",
    "train64_x = train64[1]\n",
    "train64_y = train64[2]\n",
    "\n",
    "test64_x = test64[1]\n",
    "test64_y = test64[2]\n",
    "train_pos = list()\n",
    "test_pos = list()\n",
    "\n",
    "# renumber of item and generate pos \n",
    "item_set = set()\n",
    "item_set = set()\n",
    "\n",
    "for items in train64[1]:\n",
    "    pos = list()\n",
    "    for id_ in range(len(items)):\n",
    "        item_set.add(items[id_])\n",
    "        pos.append(id_ + 1)\n",
    "    pos.append(len(items)+1)\n",
    "    train_pos.append(pos)\n",
    "\n",
    "for item in train64[2]:\n",
    "    item_set.add(item)\n",
    "\n",
    "for items in test64[1]:\n",
    "    pos = []\n",
    "    for id_ in range(len(items)):\n",
    "        item_set.add(items[id_])\n",
    "        pos.append(id_ + 1)\n",
    "    pos.append(len(items)+1)\n",
    "    test_pos.append(pos)\n",
    "    \n",
    "for item in test64[2]:\n",
    "    item_set.add(item)\n",
    "item_list = sorted(list(item_set))\n",
    "item_dict = dict()\n",
    "for i in range(1, len(item_set)+1):\n",
    "    item = item_list[i-1]\n",
    "    item_dict[item] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train64_x = list()\n",
    "train64_y = list()\n",
    "\n",
    "test64_x = list()\n",
    "test64_y = list()\n",
    "    \n",
    "for items in train64[1]:\n",
    "    new_list = []\n",
    "    for item in items:\n",
    "        new_item = item_dict[item]\n",
    "        new_list.append(new_item)\n",
    "    train64_x.append(new_list)\n",
    "for item in train64[2]:\n",
    "    new_item = item_dict[item]\n",
    "    train64_y.append(new_item)\n",
    "for items in test64[1]:\n",
    "    new_list = []\n",
    "    for item in items:\n",
    "        new_item = item_dict[item]\n",
    "        new_list.append(new_item)\n",
    "    test64_x.append(new_list)\n",
    "for item in test64[2]:\n",
    "    new_item = item_dict[item]\n",
    "    test64_y.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for sample in train64_x:\n",
    "    max_length = len(sample) if len(sample) > max_length else max_length\n",
    "for sample in test64_x:\n",
    "    max_length = len(sample) if len(sample) > max_length else max_length \n",
    "\n",
    "train_seqs = np.zeros((len(train64_x), max_length))\n",
    "train_poses = np.zeros((len(train64_x), max_length+1))\n",
    "test_seqs = np.zeros((len(test64_x), max_length))\n",
    "test_poses = np.zeros((len(test64_x), max_length+1))\n",
    "\n",
    "for i in range(len(train64_x)):\n",
    "    seq = train64_x[i]\n",
    "    pos = train_pos[i]\n",
    "    length = len(seq)\n",
    "    train_seqs[i][-length:] = seq\n",
    "    train_poses[i][-length-1:] = pos\n",
    "    \n",
    "for i in range(len(test64_x)):\n",
    "    seq = test64_x[i]\n",
    "    pos = test_pos[i]\n",
    "    length = len(seq)\n",
    "    test_seqs[i][-length:] = seq\n",
    "    test_poses[i][-length-1:] = pos\n",
    "\n",
    "target_seqs = np.array(train64_y)\n",
    "target_test_seqs = np.array(test64_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_set = set()\n",
    "for items in train64_x:\n",
    "    for item in items:\n",
    "        item_set.add(item)\n",
    "for item in train64_y:\n",
    "    item_set.add(item)\n",
    "for items in test64_x:\n",
    "    for item in items:\n",
    "        item_set.add(item)\n",
    "for item in test64_y:\n",
    "    item_set.add(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_seqs)\n",
    "train_pos = torch.Tensor(train_poses)\n",
    "train_y = torch.Tensor(target_seqs)\n",
    "test_x = torch.Tensor(test_seqs)\n",
    "test_pos = torch.Tensor(test_poses)\n",
    "test_y = torch.Tensor(target_test_seqs)\n",
    "train_label = torch.Tensor([36969]).repeat(len(train64_x)).unsqueeze(1)\n",
    "test_label = torch.Tensor([36969]).repeat(len(test64_x)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.cat((train_x, train_label), 1)\n",
    "test_x = torch.cat((test_x, test_label), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DualAttention(nn.Module):\n",
    "    def __init__(self, item_dim, pos_dim, n_items, n_pos, w, atten_way='dot', decoder_way='bilinear', dropout=0,\n",
    "                 activate='relu'):\n",
    "        super(DualAttention, self).__init__()\n",
    "        self.item_dim = item_dim\n",
    "        self.pos_dim = pos_dim\n",
    "        dim = item_dim + pos_dim\n",
    "        self.dim = dim\n",
    "        self.n_items = n_items\n",
    "        self.embedding = nn.Embedding(n_items + 1, item_dim, padding_idx=0,max_norm=1.5)\n",
    "        self.pos_embedding = nn.Embedding(n_pos, pos_dim, padding_idx=0, max_norm=1.5)\n",
    "        self.atten_way = atten_way\n",
    "        self.decoder_way = decoder_way\n",
    "        \n",
    "        self.atten_w0 = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.atten_w1 = nn.Parameter(torch.Tensor(dim, dim))\n",
    "        self.atten_w2 = nn.Parameter(torch.Tensor(dim, dim))\n",
    "        self.atten_bias = nn.Parameter(torch.Tensor(dim))\n",
    "        self.w_f = nn.Linear(2*dim, item_dim)\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.self_atten_w1 = nn.Linear(dim, dim)\n",
    "        self.self_atten_w2 = nn.Linear(dim, dim)\n",
    "        \n",
    "       \n",
    "        self.LN = nn.LayerNorm(dim)\n",
    "        self.LN2 = nn.LayerNorm(item_dim)\n",
    "        self.is_dropout = True\n",
    "        self.attention_mlp = nn.Linear(dim, dim)\n",
    "\n",
    "        self.alpha_w = nn.Linear(dim, 1)\n",
    "        \n",
    "        if activate == 'relu':\n",
    "            self.activate = F.relu\n",
    "        elif activate == 'selu':\n",
    "            self.activate = F.selu\n",
    "        self.w = w\n",
    "        self.initial_()\n",
    "\n",
    "    def initial_(self):\n",
    "        \n",
    "        init.normal_(self.atten_w0, 0, 0.05)\n",
    "        init.normal_(self.atten_w1, 0, 0.05)\n",
    "        init.normal_(self.atten_w2, 0, 0.05)\n",
    "        init.constant_(self.atten_bias, 0)\n",
    "        init.constant_(self.attention_mlp.bias, 0)\n",
    "        init.constant_(self.embedding.weight[0], 0)\n",
    "        init.constant_(self.pos_embedding.weight[0], 0)\n",
    "\n",
    "    def forward(self, x, pos):\n",
    "        self.is_dropout = True\n",
    "        x_embeddings = self.embedding(x)  # B,seq,dim\n",
    "        pos_embeddings = self.pos_embedding(pos)  # B, seq, dim\n",
    "        mask = (x != 0).float()  # B,seq\n",
    "        x_ = torch.cat((x_embeddings, pos_embeddings), 2)  # B seq, 2*dim\n",
    "        x_s = x_[:, :-1, :]  # B, seq-1, 2*dim\n",
    "        alpha_ent = self.get_alpha(x = x_[:, -1, :], number= 0)\n",
    "        m_s, x_n = self.self_attention(x_, x_, x_, mask, alpha_ent)\n",
    "        alpha_global = self.get_alpha(x= m_s, number=1)\n",
    "        global_c = self.global_attention(m_s, x_n, x_s, mask, alpha_global)  # B, 1, dim\n",
    "\n",
    "        h_t = global_c\n",
    "\n",
    "        result = self.decoder(h_t, m_s)\n",
    "       \n",
    "        return result\n",
    "    \n",
    "    def get_alpha(self, x=None, number=None):\n",
    "        if number == 0:\n",
    "            alpha_ent = torch.sigmoid(self.alpha_w(x)) + 1\n",
    "            alpha_ent = self.add_value(alpha_ent).unsqueeze(1)\n",
    "            alpha_ent = alpha_ent.expand(-1, 285, -1)\n",
    "            return alpha_ent\n",
    "        if number == 1:\n",
    "            alpha_global = torch.sigmoid(self.alpha_w(x)) + 1\n",
    "            alpha_global = self.add_value(alpha_global)\n",
    "            return alpha_global\n",
    "                \n",
    "                \n",
    "    def add_value(self, value):\n",
    "        mask_value = (value ==1).float()\n",
    "        value = value.masked_fill(mask_value == 1, 1.0001)\n",
    "        return value\n",
    "        \n",
    "    def self_attention(self, q, k, v, mask=None, alpha_ent = 1):\n",
    "        if self.is_dropout:\n",
    "            q_ = self.dropout(self.activate(self.attention_mlp(q)))\n",
    "        else:\n",
    "            q_ = self.activate(self.attention_mlp(q))\n",
    "        scores = torch.matmul(q_, k.transpose(1, 2)) / math.sqrt(self.dim)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand(-1, q.size(1), -1)\n",
    "            scores = scores.masked_fill(mask == 0, -np.inf)\n",
    "        alpha = entmax_bisect(scores, alpha_ent, dim=-1)\n",
    "        att_v = torch.matmul(alpha, v)  # B, seq, dim\n",
    "        if self.is_dropout:\n",
    "            att_v = self.dropout(self.self_atten_w2(self.activate(self.self_atten_w1(att_v)))) + att_v\n",
    "        else:\n",
    "            att_v = self.self_atten_w2(self.activate(self.self_atten_w1(att_v))) + att_v\n",
    "        att_v = self.LN(att_v)\n",
    "        c = att_v[:, -1, :].unsqueeze(1)\n",
    "        x_n = att_v[:, :-1, :]\n",
    "        return c, x_n\n",
    "\n",
    "    def global_attention(self,target,k, v, mask=None, alpha_ent=1):\n",
    "        alpha = torch.matmul(\n",
    "            torch.relu(k.matmul(self.atten_w1) + target.matmul(self.atten_w2) + self.atten_bias),\n",
    "            self.atten_w0.t())  # (B,seq,1)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(-1)\n",
    "            mask = mask[:, :-1, :]\n",
    "            alpha = alpha.masked_fill(mask == 0, -np.inf)\n",
    "        alpha = entmax_bisect(alpha, alpha_ent, dim=1)\n",
    "        c = torch.matmul(alpha.transpose(1, 2), v)  # (B, 1, dim)\n",
    "\n",
    "        return c\n",
    "\n",
    "    def decoder(self, global_c, self_c):\n",
    "        if self.is_dropout:\n",
    "            c = self.dropout(torch.selu(self.w_f(torch.cat((global_c, self_c), 2))))\n",
    "        else:\n",
    "            c = torch.selu(self.w_f(torch.cat((global_c, self_c), 2))) \n",
    "        c = c.squeeze()\n",
    "        l_c = (c/torch.norm(c, dim=-1).unsqueeze(1))\n",
    "        l_emb = self.embedding.weight[1:-1]/torch.norm(self.embedding.weight[1:-1], dim=-1).unsqueeze(1)\n",
    "        z = self.w * torch.matmul(l_c, l_emb.t())\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "    def predict(self, x, pos, k=20):\n",
    "        self.is_dropout = False\n",
    "        x_embeddings = self.embedding(x)  # B,seq,dim\n",
    "        pos_embeddings = self.pos_embedding(pos)  # B, seq, dim\n",
    "        mask = (x != 0).float()  # B,seq\n",
    "        x_ = torch.cat((x_embeddings, pos_embeddings), 2)  # B seq, 2*dim\n",
    "        x_s = x_[:, :-1, :]  # B, seq-1, 2*dim\n",
    "\n",
    "        alpha_ent = self.get_alpha(x = x_[:, -1, :], number= 0)\n",
    "        m_s, x_n = self.self_attention(x_, x_, x_, mask, alpha_ent)\n",
    "        alpha_global = self.get_alpha(x= m_s, number=1)\n",
    "        global_c = self.global_attention(m_s, x_n, x_s, mask, alpha_global)  # B, 1, dim\n",
    "\n",
    "        h_t = global_c\n",
    "\n",
    "        result = self.decoder(h_t, m_s)\n",
    "        rank = torch.argsort(result, dim=1, descending=True)\n",
    "        return rank[:, 0:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2020-09-14 14:10:44\n",
      "[00/50] [099/846] mean_loss : 12.43\n",
      "[00/50] [199/846] mean_loss : 11.50\n",
      "[00/50] [299/846] mean_loss : 11.02\n",
      "[00/50] [399/846] mean_loss : 10.73\n",
      "[00/50] [499/846] mean_loss : 10.51\n",
      "[00/50] [599/846] mean_loss : 10.34\n",
      "[00/50] [699/846] mean_loss : 10.20\n",
      "[00/50] [799/846] mean_loss : 10.07\n",
      "Recall@20: 0.3765 Recall@10: 0.3573  Recall@5:0.3404\n",
      "MRR@20:0.2734 MRR@10:0.2721 MRR@5:0.2698\n",
      "best result: 0.37648691514670896\n",
      "==================================\n",
      "2020-09-14 14:18:09\n",
      "[01/50] [099/846] mean_loss : 8.71\n",
      "[01/50] [199/846] mean_loss : 8.63\n",
      "[01/50] [299/846] mean_loss : 8.55\n",
      "[01/50] [399/846] mean_loss : 8.49\n",
      "[01/50] [499/846] mean_loss : 8.44\n",
      "[01/50] [599/846] mean_loss : 8.38\n",
      "[01/50] [699/846] mean_loss : 8.33\n",
      "[01/50] [799/846] mean_loss : 8.28\n",
      "Recall@20: 0.4408 Recall@10: 0.4076  Recall@5:0.3718\n",
      "MRR@20:0.2885 MRR@10:0.2862 MRR@5:0.2814\n",
      "best result: 0.4407877346021676\n",
      "==================================\n",
      "2020-09-14 14:25:36\n",
      "[02/50] [099/846] mean_loss : 7.51\n",
      "[02/50] [199/846] mean_loss : 7.45\n",
      "[02/50] [299/846] mean_loss : 7.40\n",
      "[02/50] [399/846] mean_loss : 7.36\n",
      "[02/50] [499/846] mean_loss : 7.33\n",
      "[02/50] [599/846] mean_loss : 7.30\n",
      "[02/50] [699/846] mean_loss : 7.27\n",
      "[02/50] [799/846] mean_loss : 7.24\n",
      "Recall@20: 0.4892 Recall@10: 0.4433  Recall@5:0.3920\n",
      "MRR@20:0.2994 MRR@10:0.2963 MRR@5:0.2893\n",
      "best result: 0.48916204070843244\n",
      "==================================\n",
      "2020-09-14 14:33:03\n",
      "[03/50] [099/846] mean_loss : 6.69\n",
      "[03/50] [199/846] mean_loss : 6.66\n",
      "[03/50] [299/846] mean_loss : 6.64\n",
      "[03/50] [399/846] mean_loss : 6.62\n",
      "[03/50] [499/846] mean_loss : 6.60\n",
      "[03/50] [599/846] mean_loss : 6.59\n",
      "[03/50] [699/846] mean_loss : 6.58\n",
      "[03/50] [799/846] mean_loss : 6.56\n",
      "Recall@20: 0.5182 Recall@10: 0.4620  Recall@5:0.4024\n",
      "MRR@20:0.3045 MRR@10:0.3006 MRR@5:0.2926\n",
      "best result: 0.5182394924662966\n",
      "==================================\n",
      "2020-09-14 14:40:31\n",
      "[04/50] [099/846] mean_loss : 6.19\n",
      "[04/50] [199/846] mean_loss : 6.16\n",
      "[04/50] [299/846] mean_loss : 6.15\n",
      "[04/50] [399/846] mean_loss : 6.14\n",
      "[04/50] [499/846] mean_loss : 6.14\n",
      "[04/50] [599/846] mean_loss : 6.13\n",
      "[04/50] [699/846] mean_loss : 6.13\n",
      "[04/50] [799/846] mean_loss : 6.12\n",
      "Recall@20: 0.5353 Recall@10: 0.4750  Recall@5:0.4077\n",
      "MRR@20:0.3069 MRR@10:0.3028 MRR@5:0.2937\n",
      "best result: 0.535289452815226\n",
      "==================================\n",
      "2020-09-14 14:48:01\n",
      "[05/50] [099/846] mean_loss : 5.86\n",
      "[05/50] [199/846] mean_loss : 5.84\n",
      "[05/50] [299/846] mean_loss : 5.83\n",
      "[05/50] [399/846] mean_loss : 5.82\n",
      "[05/50] [499/846] mean_loss : 5.82\n",
      "[05/50] [599/846] mean_loss : 5.82\n",
      "[05/50] [699/846] mean_loss : 5.82\n",
      "[05/50] [799/846] mean_loss : 5.82\n",
      "Recall@20: 0.5449 Recall@10: 0.4804  Recall@5:0.4112\n",
      "MRR@20:0.3086 MRR@10:0.3041 MRR@5:0.2947\n",
      "best result: 0.5448717948717948\n",
      "==================================\n",
      "2020-09-14 14:55:30\n",
      "[06/50] [099/846] mean_loss : 5.59\n",
      "[06/50] [199/846] mean_loss : 5.60\n",
      "[06/50] [299/846] mean_loss : 5.60\n",
      "[06/50] [399/846] mean_loss : 5.60\n",
      "[06/50] [499/846] mean_loss : 5.60\n",
      "[06/50] [599/846] mean_loss : 5.60\n",
      "[06/50] [699/846] mean_loss : 5.60\n",
      "[06/50] [799/846] mean_loss : 5.61\n",
      "Recall@20: 0.5523 Recall@10: 0.4851  Recall@5:0.4146\n",
      "MRR@20:0.3080 MRR@10:0.3033 MRR@5:0.2938\n",
      "best result: 0.552273328046524\n",
      "==================================\n",
      "2020-09-14 15:03:00\n",
      "[07/50] [099/846] mean_loss : 5.44\n",
      "[07/50] [199/846] mean_loss : 5.43\n",
      "[07/50] [299/846] mean_loss : 5.43\n",
      "[07/50] [399/846] mean_loss : 5.43\n",
      "[07/50] [499/846] mean_loss : 5.44\n",
      "[07/50] [599/846] mean_loss : 5.44\n",
      "[07/50] [699/846] mean_loss : 5.45\n",
      "[07/50] [799/846] mean_loss : 5.45\n",
      "Recall@20: 0.5554 Recall@10: 0.4870  Recall@5:0.4165\n",
      "MRR@20:0.3092 MRR@10:0.3045 MRR@5:0.2950\n",
      "best result: 0.5554454136928364\n",
      "==================================\n",
      "2020-09-14 15:10:31\n",
      "[08/50] [099/846] mean_loss : 5.30\n",
      "[08/50] [199/846] mean_loss : 5.30\n",
      "[08/50] [299/846] mean_loss : 5.30\n",
      "[08/50] [399/846] mean_loss : 5.31\n",
      "[08/50] [499/846] mean_loss : 5.32\n",
      "[08/50] [599/846] mean_loss : 5.32\n",
      "[08/50] [699/846] mean_loss : 5.32\n",
      "[08/50] [799/846] mean_loss : 5.33\n",
      "Recall@20: 0.5599 Recall@10: 0.4878  Recall@5:0.4166\n",
      "MRR@20:0.3095 MRR@10:0.3045 MRR@5:0.2949\n",
      "best result: 0.5598731165741475\n",
      "==================================\n",
      "2020-09-14 15:18:00\n",
      "[09/50] [099/846] mean_loss : 5.21\n",
      "[09/50] [199/846] mean_loss : 5.20\n",
      "[09/50] [299/846] mean_loss : 5.20\n",
      "[09/50] [399/846] mean_loss : 5.20\n",
      "[09/50] [499/846] mean_loss : 5.21\n",
      "[09/50] [599/846] mean_loss : 5.22\n",
      "[09/50] [699/846] mean_loss : 5.23\n",
      "[09/50] [799/846] mean_loss : 5.23\n",
      "Recall@20: 0.5639 Recall@10: 0.4909  Recall@5:0.4182\n",
      "MRR@20:0.3093 MRR@10:0.3042 MRR@5:0.2945\n",
      "best result: 0.5639043087496696\n",
      "==================================\n",
      "2020-09-14 15:25:30\n",
      "[10/50] [099/846] mean_loss : 5.12\n",
      "[10/50] [199/846] mean_loss : 5.12\n",
      "[10/50] [299/846] mean_loss : 5.12\n",
      "[10/50] [399/846] mean_loss : 5.12\n",
      "[10/50] [499/846] mean_loss : 5.13\n",
      "[10/50] [599/846] mean_loss : 5.14\n",
      "[10/50] [699/846] mean_loss : 5.15\n",
      "[10/50] [799/846] mean_loss : 5.16\n",
      "Recall@20: 0.5642 Recall@10: 0.4911  Recall@5:0.4163\n",
      "MRR@20:0.3083 MRR@10:0.3032 MRR@5:0.2931\n",
      "best result: 0.5641686492201956\n",
      "==================================\n",
      "2020-09-14 15:33:00\n",
      "[11/50] [099/846] mean_loss : 5.05\n",
      "[11/50] [199/846] mean_loss : 5.04\n",
      "[11/50] [299/846] mean_loss : 5.05\n",
      "[11/50] [399/846] mean_loss : 5.06\n",
      "[11/50] [499/846] mean_loss : 5.07\n",
      "[11/50] [599/846] mean_loss : 5.08\n",
      "[11/50] [699/846] mean_loss : 5.08\n",
      "[11/50] [799/846] mean_loss : 5.09\n",
      "Recall@20: 0.5638 Recall@10: 0.4898  Recall@5:0.4159\n",
      "MRR@20:0.3083 MRR@10:0.3031 MRR@5:0.2932\n",
      "best result: 0.5641686492201956\n",
      "==================================\n",
      "2020-09-14 15:40:29\n",
      "[12/50] [099/846] mean_loss : 4.98\n",
      "[12/50] [199/846] mean_loss : 4.98\n",
      "[12/50] [299/846] mean_loss : 4.99\n",
      "[12/50] [399/846] mean_loss : 5.00\n",
      "[12/50] [499/846] mean_loss : 5.01\n",
      "[12/50] [599/846] mean_loss : 5.02\n",
      "[12/50] [699/846] mean_loss : 5.03\n",
      "[12/50] [799/846] mean_loss : 5.04\n",
      "Recall@20: 0.5662 Recall@10: 0.4894  Recall@5:0.4159\n",
      "MRR@20:0.3070 MRR@10:0.3017 MRR@5:0.2917\n",
      "best result: 0.5662172878667724\n",
      "==================================\n",
      "2020-09-14 15:47:03\n",
      "[13/50] [099/846] mean_loss : 4.95\n",
      "[13/50] [199/846] mean_loss : 4.94\n",
      "[13/50] [299/846] mean_loss : 4.95\n",
      "[13/50] [399/846] mean_loss : 4.96\n",
      "[13/50] [499/846] mean_loss : 4.97\n",
      "[13/50] [599/846] mean_loss : 4.98\n",
      "[13/50] [699/846] mean_loss : 4.98\n",
      "[13/50] [799/846] mean_loss : 4.99\n",
      "Recall@20: 0.5663 Recall@10: 0.4879  Recall@5:0.4167\n",
      "MRR@20:0.3071 MRR@10:0.3017 MRR@5:0.2921\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 15:51:22\n",
      "[14/50] [099/846] mean_loss : 4.90\n",
      "[14/50] [199/846] mean_loss : 4.89\n",
      "[14/50] [299/846] mean_loss : 4.91\n",
      "[14/50] [399/846] mean_loss : 4.91\n",
      "[14/50] [499/846] mean_loss : 4.92\n",
      "[14/50] [599/846] mean_loss : 4.93\n",
      "[14/50] [699/846] mean_loss : 4.94\n",
      "[14/50] [799/846] mean_loss : 4.95\n",
      "Recall@20: 0.5630 Recall@10: 0.4888  Recall@5:0.4143\n",
      "MRR@20:0.3056 MRR@10:0.3005 MRR@5:0.2905\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 15:55:41\n",
      "[15/50] [099/846] mean_loss : 4.87\n",
      "[15/50] [199/846] mean_loss : 4.87\n",
      "[15/50] [299/846] mean_loss : 4.87\n",
      "[15/50] [399/846] mean_loss : 4.87\n",
      "[15/50] [499/846] mean_loss : 4.88\n",
      "[15/50] [599/846] mean_loss : 4.89\n",
      "[15/50] [699/846] mean_loss : 4.90\n",
      "[15/50] [799/846] mean_loss : 4.91\n",
      "Recall@20: 0.5635 Recall@10: 0.4898  Recall@5:0.4114\n",
      "MRR@20:0.3064 MRR@10:0.3013 MRR@5:0.2909\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:00:00\n",
      "[16/50] [099/846] mean_loss : 4.85\n",
      "[16/50] [199/846] mean_loss : 4.84\n",
      "[16/50] [299/846] mean_loss : 4.85\n",
      "[16/50] [399/846] mean_loss : 4.85\n",
      "[16/50] [499/846] mean_loss : 4.86\n",
      "[16/50] [599/846] mean_loss : 4.86\n",
      "[16/50] [699/846] mean_loss : 4.87\n",
      "[16/50] [799/846] mean_loss : 4.88\n",
      "Recall@20: 0.5628 Recall@10: 0.4888  Recall@5:0.4119\n",
      "MRR@20:0.3051 MRR@10:0.3000 MRR@5:0.2897\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:04:19\n",
      "[17/50] [099/846] mean_loss : 4.79\n",
      "[17/50] [199/846] mean_loss : 4.79\n",
      "[17/50] [299/846] mean_loss : 4.80\n",
      "[17/50] [399/846] mean_loss : 4.81\n",
      "[17/50] [499/846] mean_loss : 4.82\n",
      "[17/50] [599/846] mean_loss : 4.83\n",
      "[17/50] [699/846] mean_loss : 4.84\n",
      "[17/50] [799/846] mean_loss : 4.85\n",
      "Recall@20: 0.5627 Recall@10: 0.4878  Recall@5:0.4120\n",
      "MRR@20:0.3037 MRR@10:0.2985 MRR@5:0.2883\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:08:37\n",
      "[18/50] [099/846] mean_loss : 4.78\n",
      "[18/50] [199/846] mean_loss : 4.77\n",
      "[18/50] [299/846] mean_loss : 4.78\n",
      "[18/50] [399/846] mean_loss : 4.79\n",
      "[18/50] [499/846] mean_loss : 4.80\n",
      "[18/50] [599/846] mean_loss : 4.81\n",
      "[18/50] [699/846] mean_loss : 4.81\n",
      "[18/50] [799/846] mean_loss : 4.83\n",
      "Recall@20: 0.5639 Recall@10: 0.4861  Recall@5:0.4103\n",
      "MRR@20:0.3029 MRR@10:0.2974 MRR@5:0.2873\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:12:56\n",
      "[19/50] [099/846] mean_loss : 4.73\n",
      "[19/50] [199/846] mean_loss : 4.74\n",
      "[19/50] [299/846] mean_loss : 4.75\n",
      "[19/50] [399/846] mean_loss : 4.76\n",
      "[19/50] [499/846] mean_loss : 4.77\n",
      "[19/50] [599/846] mean_loss : 4.79\n",
      "[19/50] [699/846] mean_loss : 4.79\n",
      "[19/50] [799/846] mean_loss : 4.80\n",
      "Recall@20: 0.5617 Recall@10: 0.4869  Recall@5:0.4079\n",
      "MRR@20:0.3024 MRR@10:0.2972 MRR@5:0.2866\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:17:15\n",
      "[20/50] [099/846] mean_loss : 4.74\n",
      "[20/50] [199/846] mean_loss : 4.72\n",
      "[20/50] [299/846] mean_loss : 4.73\n",
      "[20/50] [399/846] mean_loss : 4.74\n",
      "[20/50] [499/846] mean_loss : 4.75\n",
      "[20/50] [599/846] mean_loss : 4.76\n",
      "[20/50] [699/846] mean_loss : 4.77\n",
      "[20/50] [799/846] mean_loss : 4.78\n",
      "Recall@20: 0.5623 Recall@10: 0.4869  Recall@5:0.4078\n",
      "MRR@20:0.3026 MRR@10:0.2974 MRR@5:0.2868\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:21:33\n",
      "[21/50] [099/846] mean_loss : 4.71\n",
      "[21/50] [199/846] mean_loss : 4.70\n",
      "[21/50] [299/846] mean_loss : 4.70\n",
      "[21/50] [399/846] mean_loss : 4.71\n",
      "[21/50] [499/846] mean_loss : 4.72\n",
      "[21/50] [599/846] mean_loss : 4.74\n",
      "[21/50] [699/846] mean_loss : 4.75\n",
      "[21/50] [799/846] mean_loss : 4.76\n",
      "Recall@20: 0.5605 Recall@10: 0.4841  Recall@5:0.4048\n",
      "MRR@20:0.3011 MRR@10:0.2957 MRR@5:0.2851\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:25:51\n",
      "[22/50] [099/846] mean_loss : 4.68\n",
      "[22/50] [199/846] mean_loss : 4.68\n",
      "[22/50] [299/846] mean_loss : 4.69\n",
      "[22/50] [399/846] mean_loss : 4.70\n",
      "[22/50] [499/846] mean_loss : 4.71\n",
      "[22/50] [599/846] mean_loss : 4.72\n",
      "[22/50] [699/846] mean_loss : 4.73\n",
      "[22/50] [799/846] mean_loss : 4.74\n",
      "Recall@20: 0.5599 Recall@10: 0.4832  Recall@5:0.4033\n",
      "MRR@20:0.2996 MRR@10:0.2942 MRR@5:0.2835\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:30:10\n",
      "[23/50] [099/846] mean_loss : 4.68\n",
      "[23/50] [199/846] mean_loss : 4.67\n",
      "[23/50] [299/846] mean_loss : 4.68\n",
      "[23/50] [399/846] mean_loss : 4.68\n",
      "[23/50] [499/846] mean_loss : 4.69\n",
      "[23/50] [599/846] mean_loss : 4.70\n",
      "[23/50] [699/846] mean_loss : 4.71\n",
      "[23/50] [799/846] mean_loss : 4.72\n",
      "Recall@20: 0.5578 Recall@10: 0.4803  Recall@5:0.4033\n",
      "MRR@20:0.2974 MRR@10:0.2920 MRR@5:0.2817\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:34:28\n",
      "[24/50] [099/846] mean_loss : 4.62\n",
      "[24/50] [199/846] mean_loss : 4.63\n",
      "[24/50] [299/846] mean_loss : 4.64\n",
      "[24/50] [399/846] mean_loss : 4.65\n",
      "[24/50] [499/846] mean_loss : 4.67\n",
      "[24/50] [599/846] mean_loss : 4.68\n",
      "[24/50] [699/846] mean_loss : 4.69\n",
      "[24/50] [799/846] mean_loss : 4.70\n",
      "Recall@20: 0.5554 Recall@10: 0.4798  Recall@5:0.4022\n",
      "MRR@20:0.2986 MRR@10:0.2933 MRR@5:0.2828\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:38:47\n",
      "[25/50] [099/846] mean_loss : 4.62\n",
      "[25/50] [199/846] mean_loss : 4.62\n",
      "[25/50] [299/846] mean_loss : 4.63\n",
      "[25/50] [399/846] mean_loss : 4.64\n",
      "[25/50] [499/846] mean_loss : 4.65\n",
      "[25/50] [599/846] mean_loss : 4.66\n",
      "[25/50] [699/846] mean_loss : 4.67\n",
      "[25/50] [799/846] mean_loss : 4.69\n",
      "Recall@20: 0.5562 Recall@10: 0.4803  Recall@5:0.4014\n",
      "MRR@20:0.2986 MRR@10:0.2934 MRR@5:0.2828\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:43:05\n",
      "[26/50] [099/846] mean_loss : 4.60\n",
      "[26/50] [199/846] mean_loss : 4.62\n",
      "[26/50] [299/846] mean_loss : 4.63\n",
      "[26/50] [399/846] mean_loss : 4.64\n",
      "[26/50] [499/846] mean_loss : 4.65\n",
      "[26/50] [599/846] mean_loss : 4.66\n",
      "[26/50] [699/846] mean_loss : 4.66\n",
      "[26/50] [799/846] mean_loss : 4.67\n",
      "Recall@20: 0.5565 Recall@10: 0.4794  Recall@5:0.3987\n",
      "MRR@20:0.2958 MRR@10:0.2905 MRR@5:0.2796\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:47:24\n",
      "[27/50] [099/846] mean_loss : 4.61\n",
      "[27/50] [199/846] mean_loss : 4.60\n",
      "[27/50] [299/846] mean_loss : 4.60\n",
      "[27/50] [399/846] mean_loss : 4.61\n",
      "[27/50] [499/846] mean_loss : 4.62\n",
      "[27/50] [599/846] mean_loss : 4.64\n",
      "[27/50] [699/846] mean_loss : 4.64\n",
      "[27/50] [799/846] mean_loss : 4.66\n",
      "Recall@20: 0.5539 Recall@10: 0.4789  Recall@5:0.3979\n",
      "MRR@20:0.2967 MRR@10:0.2915 MRR@5:0.2806\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:51:42\n",
      "[28/50] [099/846] mean_loss : 4.59\n",
      "[28/50] [199/846] mean_loss : 4.58\n",
      "[28/50] [299/846] mean_loss : 4.59\n",
      "[28/50] [399/846] mean_loss : 4.60\n",
      "[28/50] [499/846] mean_loss : 4.61\n",
      "[28/50] [599/846] mean_loss : 4.62\n",
      "[28/50] [699/846] mean_loss : 4.63\n",
      "[28/50] [799/846] mean_loss : 4.64\n",
      "Recall@20: 0.5525 Recall@10: 0.4782  Recall@5:0.3972\n",
      "MRR@20:0.2957 MRR@10:0.2906 MRR@5:0.2797\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 16:56:00\n",
      "[29/50] [099/846] mean_loss : 4.55\n",
      "[29/50] [199/846] mean_loss : 4.56\n",
      "[29/50] [299/846] mean_loss : 4.57\n",
      "[29/50] [399/846] mean_loss : 4.58\n",
      "[29/50] [499/846] mean_loss : 4.59\n",
      "[29/50] [599/846] mean_loss : 4.61\n",
      "[29/50] [699/846] mean_loss : 4.62\n",
      "[29/50] [799/846] mean_loss : 4.63\n",
      "Recall@20: 0.5511 Recall@10: 0.4758  Recall@5:0.3955\n",
      "MRR@20:0.2939 MRR@10:0.2886 MRR@5:0.2778\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:00:19\n",
      "[30/50] [099/846] mean_loss : 4.55\n",
      "[30/50] [199/846] mean_loss : 4.56\n",
      "[30/50] [299/846] mean_loss : 4.56\n",
      "[30/50] [399/846] mean_loss : 4.57\n",
      "[30/50] [499/846] mean_loss : 4.58\n",
      "[30/50] [599/846] mean_loss : 4.60\n",
      "[30/50] [699/846] mean_loss : 4.61\n",
      "[30/50] [799/846] mean_loss : 4.62\n",
      "Recall@20: 0.5504 Recall@10: 0.4752  Recall@5:0.3944\n",
      "MRR@20:0.2935 MRR@10:0.2883 MRR@5:0.2774\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:04:37\n",
      "[31/50] [099/846] mean_loss : 4.55\n",
      "[31/50] [199/846] mean_loss : 4.54\n",
      "[31/50] [299/846] mean_loss : 4.55\n",
      "[31/50] [399/846] mean_loss : 4.56\n",
      "[31/50] [499/846] mean_loss : 4.57\n",
      "[31/50] [599/846] mean_loss : 4.58\n",
      "[31/50] [699/846] mean_loss : 4.60\n",
      "[31/50] [799/846] mean_loss : 4.61\n",
      "Recall@20: 0.5496 Recall@10: 0.4732  Recall@5:0.3946\n",
      "MRR@20:0.2915 MRR@10:0.2862 MRR@5:0.2756\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:08:56\n",
      "[32/50] [099/846] mean_loss : 4.53\n",
      "[32/50] [199/846] mean_loss : 4.53\n",
      "[32/50] [299/846] mean_loss : 4.54\n",
      "[32/50] [399/846] mean_loss : 4.55\n",
      "[32/50] [499/846] mean_loss : 4.56\n",
      "[32/50] [599/846] mean_loss : 4.57\n",
      "[32/50] [699/846] mean_loss : 4.58\n",
      "[32/50] [799/846] mean_loss : 4.59\n",
      "Recall@20: 0.5473 Recall@10: 0.4710  Recall@5:0.3946\n",
      "MRR@20:0.2916 MRR@10:0.2863 MRR@5:0.2760\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:13:14\n",
      "[33/50] [099/846] mean_loss : 4.52\n",
      "[33/50] [199/846] mean_loss : 4.51\n",
      "[33/50] [299/846] mean_loss : 4.53\n",
      "[33/50] [399/846] mean_loss : 4.54\n",
      "[33/50] [499/846] mean_loss : 4.55\n",
      "[33/50] [599/846] mean_loss : 4.56\n",
      "[33/50] [699/846] mean_loss : 4.57\n",
      "[33/50] [799/846] mean_loss : 4.58\n",
      "Recall@20: 0.5482 Recall@10: 0.4704  Recall@5:0.3919\n",
      "MRR@20:0.2904 MRR@10:0.2850 MRR@5:0.2745\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:17:32\n",
      "[34/50] [099/846] mean_loss : 4.52\n",
      "[34/50] [199/846] mean_loss : 4.51\n",
      "[34/50] [299/846] mean_loss : 4.52\n",
      "[34/50] [399/846] mean_loss : 4.53\n",
      "[34/50] [499/846] mean_loss : 4.54\n",
      "[34/50] [599/846] mean_loss : 4.55\n",
      "[34/50] [699/846] mean_loss : 4.56\n",
      "[34/50] [799/846] mean_loss : 4.57\n",
      "Recall@20: 0.5450 Recall@10: 0.4683  Recall@5:0.3893\n",
      "MRR@20:0.2900 MRR@10:0.2847 MRR@5:0.2741\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:21:51\n",
      "[35/50] [099/846] mean_loss : 4.50\n",
      "[35/50] [199/846] mean_loss : 4.51\n",
      "[35/50] [299/846] mean_loss : 4.51\n",
      "[35/50] [399/846] mean_loss : 4.52\n",
      "[35/50] [499/846] mean_loss : 4.54\n",
      "[35/50] [599/846] mean_loss : 4.54\n",
      "[35/50] [699/846] mean_loss : 4.55\n",
      "[35/50] [799/846] mean_loss : 4.56\n",
      "Recall@20: 0.5445 Recall@10: 0.4699  Recall@5:0.3900\n",
      "MRR@20:0.2891 MRR@10:0.2839 MRR@5:0.2731\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:26:09\n",
      "[36/50] [099/846] mean_loss : 4.49\n",
      "[36/50] [199/846] mean_loss : 4.49\n",
      "[36/50] [299/846] mean_loss : 4.50\n",
      "[36/50] [399/846] mean_loss : 4.51\n",
      "[36/50] [499/846] mean_loss : 4.52\n",
      "[36/50] [599/846] mean_loss : 4.53\n",
      "[36/50] [699/846] mean_loss : 4.54\n",
      "[36/50] [799/846] mean_loss : 4.55\n",
      "Recall@20: 0.5449 Recall@10: 0.4686  Recall@5:0.3883\n",
      "MRR@20:0.2876 MRR@10:0.2823 MRR@5:0.2714\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:30:27\n",
      "[37/50] [099/846] mean_loss : 4.48\n",
      "[37/50] [199/846] mean_loss : 4.48\n",
      "[37/50] [299/846] mean_loss : 4.48\n",
      "[37/50] [399/846] mean_loss : 4.49\n",
      "[37/50] [499/846] mean_loss : 4.51\n",
      "[37/50] [599/846] mean_loss : 4.52\n",
      "[37/50] [699/846] mean_loss : 4.53\n",
      "[37/50] [799/846] mean_loss : 4.54\n",
      "Recall@20: 0.5428 Recall@10: 0.4654  Recall@5:0.3885\n",
      "MRR@20:0.2871 MRR@10:0.2817 MRR@5:0.2715\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:34:46\n",
      "[38/50] [099/846] mean_loss : 4.47\n",
      "[38/50] [199/846] mean_loss : 4.47\n",
      "[38/50] [299/846] mean_loss : 4.48\n",
      "[38/50] [399/846] mean_loss : 4.49\n",
      "[38/50] [499/846] mean_loss : 4.50\n",
      "[38/50] [599/846] mean_loss : 4.51\n",
      "[38/50] [699/846] mean_loss : 4.52\n",
      "[38/50] [799/846] mean_loss : 4.53\n",
      "Recall@20: 0.5437 Recall@10: 0.4666  Recall@5:0.3853\n",
      "MRR@20:0.2875 MRR@10:0.2821 MRR@5:0.2711\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:39:04\n",
      "[39/50] [099/846] mean_loss : 4.48\n",
      "[39/50] [199/846] mean_loss : 4.48\n",
      "[39/50] [299/846] mean_loss : 4.49\n",
      "[39/50] [399/846] mean_loss : 4.49\n",
      "[39/50] [499/846] mean_loss : 4.50\n",
      "[39/50] [599/846] mean_loss : 4.51\n",
      "[39/50] [699/846] mean_loss : 4.52\n",
      "[39/50] [799/846] mean_loss : 4.52\n",
      "Recall@20: 0.5413 Recall@10: 0.4642  Recall@5:0.3840\n",
      "MRR@20:0.2856 MRR@10:0.2802 MRR@5:0.2695\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:43:23\n",
      "[40/50] [099/846] mean_loss : 4.45\n",
      "[40/50] [199/846] mean_loss : 4.44\n",
      "[40/50] [299/846] mean_loss : 4.46\n",
      "[40/50] [399/846] mean_loss : 4.46\n",
      "[40/50] [499/846] mean_loss : 4.48\n",
      "[40/50] [599/846] mean_loss : 4.49\n",
      "[40/50] [699/846] mean_loss : 4.50\n",
      "[40/50] [799/846] mean_loss : 4.51\n",
      "Recall@20: 0.5417 Recall@10: 0.4644  Recall@5:0.3854\n",
      "MRR@20:0.2864 MRR@10:0.2810 MRR@5:0.2705\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:47:41\n",
      "[41/50] [099/846] mean_loss : 4.43\n",
      "[41/50] [199/846] mean_loss : 4.44\n",
      "[41/50] [299/846] mean_loss : 4.45\n",
      "[41/50] [399/846] mean_loss : 4.46\n",
      "[41/50] [499/846] mean_loss : 4.47\n",
      "[41/50] [599/846] mean_loss : 4.48\n",
      "[41/50] [699/846] mean_loss : 4.49\n",
      "[41/50] [799/846] mean_loss : 4.51\n",
      "Recall@20: 0.5424 Recall@10: 0.4636  Recall@5:0.3824\n",
      "MRR@20:0.2845 MRR@10:0.2791 MRR@5:0.2682\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:51:59\n",
      "[42/50] [099/846] mean_loss : 4.44\n",
      "[42/50] [199/846] mean_loss : 4.43\n",
      "[42/50] [299/846] mean_loss : 4.44\n",
      "[42/50] [399/846] mean_loss : 4.45\n",
      "[42/50] [499/846] mean_loss : 4.46\n",
      "[42/50] [599/846] mean_loss : 4.47\n",
      "[42/50] [699/846] mean_loss : 4.48\n",
      "[42/50] [799/846] mean_loss : 4.49\n",
      "Recall@20: 0.5401 Recall@10: 0.4627  Recall@5:0.3845\n",
      "MRR@20:0.2854 MRR@10:0.2800 MRR@5:0.2695\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 17:56:18\n",
      "[43/50] [099/846] mean_loss : 4.41\n",
      "[43/50] [199/846] mean_loss : 4.41\n",
      "[43/50] [299/846] mean_loss : 4.43\n",
      "[43/50] [399/846] mean_loss : 4.44\n",
      "[43/50] [499/846] mean_loss : 4.45\n",
      "[43/50] [599/846] mean_loss : 4.47\n",
      "[43/50] [699/846] mean_loss : 4.48\n",
      "[43/50] [799/846] mean_loss : 4.49\n",
      "Recall@20: 0.5396 Recall@10: 0.4607  Recall@5:0.3828\n",
      "MRR@20:0.2839 MRR@10:0.2784 MRR@5:0.2680\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:00:36\n",
      "[44/50] [099/846] mean_loss : 4.43\n",
      "[44/50] [199/846] mean_loss : 4.42\n",
      "[44/50] [299/846] mean_loss : 4.43\n",
      "[44/50] [399/846] mean_loss : 4.43\n",
      "[44/50] [499/846] mean_loss : 4.45\n",
      "[44/50] [599/846] mean_loss : 4.46\n",
      "[44/50] [699/846] mean_loss : 4.47\n",
      "[44/50] [799/846] mean_loss : 4.48\n",
      "Recall@20: 0.5382 Recall@10: 0.4600  Recall@5:0.3824\n",
      "MRR@20:0.2839 MRR@10:0.2784 MRR@5:0.2679\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:04:54\n",
      "[45/50] [099/846] mean_loss : 4.41\n",
      "[45/50] [199/846] mean_loss : 4.41\n",
      "[45/50] [299/846] mean_loss : 4.41\n",
      "[45/50] [399/846] mean_loss : 4.43\n",
      "[45/50] [499/846] mean_loss : 4.44\n",
      "[45/50] [599/846] mean_loss : 4.45\n",
      "[45/50] [699/846] mean_loss : 4.46\n",
      "[45/50] [799/846] mean_loss : 4.47\n",
      "Recall@20: 0.5379 Recall@10: 0.4601  Recall@5:0.3816\n",
      "MRR@20:0.2831 MRR@10:0.2776 MRR@5:0.2672\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:09:13\n",
      "[46/50] [099/846] mean_loss : 4.38\n",
      "[46/50] [199/846] mean_loss : 4.39\n",
      "[46/50] [299/846] mean_loss : 4.40\n",
      "[46/50] [399/846] mean_loss : 4.42\n",
      "[46/50] [499/846] mean_loss : 4.43\n",
      "[46/50] [599/846] mean_loss : 4.44\n",
      "[46/50] [699/846] mean_loss : 4.45\n",
      "[46/50] [799/846] mean_loss : 4.46\n",
      "Recall@20: 0.5352 Recall@10: 0.4564  Recall@5:0.3807\n",
      "MRR@20:0.2815 MRR@10:0.2760 MRR@5:0.2659\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:13:31\n",
      "[47/50] [099/846] mean_loss : 4.40\n",
      "[47/50] [199/846] mean_loss : 4.39\n",
      "[47/50] [299/846] mean_loss : 4.40\n",
      "[47/50] [399/846] mean_loss : 4.41\n",
      "[47/50] [499/846] mean_loss : 4.42\n",
      "[47/50] [599/846] mean_loss : 4.44\n",
      "[47/50] [699/846] mean_loss : 4.45\n",
      "[47/50] [799/846] mean_loss : 4.46\n",
      "Recall@20: 0.5350 Recall@10: 0.4570  Recall@5:0.3796\n",
      "MRR@20:0.2813 MRR@10:0.2759 MRR@5:0.2656\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:17:49\n",
      "[48/50] [099/846] mean_loss : 4.40\n",
      "[48/50] [199/846] mean_loss : 4.38\n",
      "[48/50] [299/846] mean_loss : 4.39\n",
      "[48/50] [399/846] mean_loss : 4.41\n",
      "[48/50] [499/846] mean_loss : 4.42\n",
      "[48/50] [599/846] mean_loss : 4.42\n",
      "[48/50] [699/846] mean_loss : 4.44\n",
      "[48/50] [799/846] mean_loss : 4.45\n",
      "Recall@20: 0.5344 Recall@10: 0.4572  Recall@5:0.3796\n",
      "MRR@20:0.2801 MRR@10:0.2747 MRR@5:0.2643\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "2020-09-14 18:22:07\n",
      "[49/50] [099/846] mean_loss : 4.38\n",
      "[49/50] [199/846] mean_loss : 4.37\n",
      "[49/50] [299/846] mean_loss : 4.38\n",
      "[49/50] [399/846] mean_loss : 4.39\n",
      "[49/50] [499/846] mean_loss : 4.41\n",
      "[49/50] [599/846] mean_loss : 4.42\n",
      "[49/50] [699/846] mean_loss : 4.43\n",
      "[49/50] [799/846] mean_loss : 4.44\n",
      "Recall@20: 0.5326 Recall@10: 0.4561  Recall@5:0.3749\n",
      "MRR@20:0.2797 MRR@10:0.2744 MRR@5:0.2635\n",
      "best result: 0.5662833729844039\n",
      "==================================\n",
      "[[0.4166666666666667, 0.48790642347343377, 0.5662833729844039, tensor(0.2921), tensor(0.3017), tensor(0.3071, device='cuda:0')]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "w_list = [20]\n",
    "record = list()\n",
    "for w in w_list:\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    train_sets = TensorDataset(train_x.long(), train_pos.long(), train_y.long())\n",
    "    train_dataload = DataLoader(train_sets, batch_size=512, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    test_x, test_pos, test_y = test_x.long(), test_pos.long(), test_y.long()\n",
    "    all_test_sets = TensorDataset(test_x, test_pos, test_y)\n",
    "    test_dataload = DataLoader(all_test_sets, batch_size=512,shuffle=False)\n",
    "    model = DualAttention(100, 100, 36970, 286, w, atten_way='MLP', decoder_way='trilinear2', dropout=0.5).cuda()\n",
    "    opti = optim.Adam(model.parameters(), lr=0.001, weight_decay=0, amsgrad=True)\n",
    "   \n",
    "    best_result = 0\n",
    "    total_time = 0\n",
    "    best_result_5 = 0\n",
    "    best_result_ = []\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        start_time = datetime.datetime.now()\n",
    "        print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        losses = 0\n",
    "        for step, (x_train, pos_train, y_train) in enumerate(train_dataload):\n",
    "            opti.zero_grad()\n",
    "            q = model(x_train.cuda(), pos_train.cuda())\n",
    "            loss = criterion(q, y_train.cuda()-1)\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            losses += loss.item()\n",
    "            if (step + 1) % 100 == 0:\n",
    "                # 打印迭代轮次与训练时间\n",
    "                print(\"[%02d/%d] [%03d/%d] mean_loss : %0.2f\" % (epoch, 50, step, len(train_sets) / 512, losses / step + 1))\n",
    "        # 打印每个epoch 训练效果\n",
    "        # scheduler.step()\n",
    "        end_time = datetime.datetime.now()\n",
    "        with torch.no_grad():\n",
    "            y_pre_all = torch.LongTensor().cuda()\n",
    "            y_pre_all_10 = torch.LongTensor()\n",
    "            y_pre_all_5 = torch.LongTensor()\n",
    "            for x_test, pos_test, y_test in test_dataload:\n",
    "                with torch.no_grad():\n",
    "                    y_pre = model.predict(x_test.cuda(), pos_test.cuda(), 20)\n",
    "                    y_pre_all = torch.cat((y_pre_all, y_pre), 0)\n",
    "                    y_pre_all_10 = torch.cat((y_pre_all_10, y_pre.cpu()[:, :10]), 0)\n",
    "                    y_pre_all_5 = torch.cat((y_pre_all_5, y_pre.cpu()[:, :5]), 0)\n",
    "            recall = get_recall(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "            recall_10 = get_recall(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "            recall_5 = get_recall(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "            mrr = get_mrr(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "            mrr_10 = get_mrr(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "            mrr_5 = get_mrr(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "    \n",
    "            print(\"Recall@20: \" + \"%.4f\" %recall + \" Recall@10: \" + \"%.4f\" %recall_10 +\"  Recall@5:\" + \"%.4f\" %recall_5)\n",
    "            print(\"MRR@20:\" + \"%.4f\" % mrr.tolist() + \" MRR@10:\" + \"%.4f\" % mrr_10.tolist() + \" MRR@5:\" + \"%.4f\" % mrr_5.tolist())\n",
    "            if best_result < recall:\n",
    "                best_result = recall\n",
    "                best_result_ = [recall_5, recall_10, recall, mrr_5, mrr_10, mrr]\n",
    "                # torch.save(model.state_dict(), 'BestModel/best_RR_w_%s.pth' % str(w))\n",
    "            print(\"best result: \" + str(best_result))\n",
    "            print(\"==================================\")\n",
    "    record.append(best_result_)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Recall@20: 0.5654 Recall@10: 0.4905  Recall@5:0.4153\n",
      "MRR@20:0.3074 MRR@10:0.3021 MRR@5:0.2920\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "model = DualAttention(100, 100, 36970, 286, 20, atten_way='MLP', decoder_way='trilinear2', dropout=0.5).cuda()\n",
    "model.load_state_dict(torch.load('BestModel/best_RR_w_20.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pre_all = torch.LongTensor().cuda()\n",
    "    y_pre_all_10 = torch.LongTensor()\n",
    "    y_pre_all_5 = torch.LongTensor()\n",
    "    for x_test, pos_test, y_test in test_dataload:\n",
    "        with torch.no_grad():\n",
    "            y_pre = model.predict(x_test.cuda(), pos_test.cuda(), 20)\n",
    "            y_pre_all = torch.cat((y_pre_all, y_pre), 0)\n",
    "            y_pre_all_10 = torch.cat((y_pre_all_10, y_pre.cpu()[:, :10]), 0)\n",
    "            y_pre_all_5 = torch.cat((y_pre_all_5, y_pre.cpu()[:, :5]), 0)\n",
    "    recall = get_recall(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "    recall_10 = get_recall(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "    recall_5 = get_recall(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "    mrr = get_mrr(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "    mrr_10 = get_mrr(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "    mrr_5 = get_mrr(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "\n",
    "    print(\"Recall@20: \" + \"%.4f\" %recall + \" Recall@10: \" + \"%.4f\" %recall_10 +\"  Recall@5:\" + \"%.4f\" %recall_5)\n",
    "    print(\"MRR@20:\" + \"%.4f\" % mrr.tolist() + \" MRR@10:\" + \"%.4f\" % mrr_10.tolist() + \" MRR@5:\" + \"%.4f\" % mrr_5.tolist())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "yjh",
   "language": "python",
   "display_name": "yjh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}