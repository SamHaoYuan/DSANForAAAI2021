{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "diginetica\n",
      "-- Starting @ 2020-09-14 14:00:39.076059s\n",
      "-- Reading data @ 2020-09-14 14:00:45.774557s\n",
      "Splitting date 1464105600.0\n",
      "Train Session Length: 132501\n",
      "Test Session Length: 11371\n",
      "[('4741', 1451577600.0), ('4747', 1451577600.0), ('4748', 1451577600.0)]\n",
      "[('289', 1464192000.0), ('302', 1464192000.0), ('1862', 1464192000.0)]\n",
      "-- Splitting train set and test set @ 2020-09-14 14:00:46.534758s\n",
      "obtain_tra-------item_num= 40841\n",
      "training sessions =  526135\n",
      "testing sessions =  44279\n",
      "[[1, 2], [4, 5, 6, 6, 7, 8], [4, 5, 6, 6, 7]] [1451577600, 1451577600, 1451577600] [3, 9, 8]\n",
      "[[19824, 18402, 9756, 19834, 19834], [19824, 18402, 9756, 19834], [19824, 18402, 9756]] [1464192000, 1464192000, 1464192000] [33829, 19834, 19834]\n",
      "all clicks:  858108\n",
      "avg length:  5.965421593776721\n",
      "Done.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#!/usr/bin/env python36\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "import operator\n",
    "import datetime\n",
    "import os\n",
    "class datatype:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "\n",
    "opt = datatype('diginetica')\n",
    "# opt.dataset = 'diginetica'\n",
    "print(opt.dataset)\n",
    "# opt.dataset = 'retailrocket'\n",
    "if opt.dataset == 'diginetica':\n",
    "    dataset = './data/diginetica/train-item-views.csv'\n",
    "elif opt.dataset == 'retailrocket':\n",
    "    dataset = './data/retailrocket/events_train_full.0.txt'\n",
    "\n",
    "print(\"-- Starting @ %ss\" % datetime.datetime.now())\n",
    "with open(dataset, \"r\") as f:\n",
    "    if opt.dataset == 'retailrocket':\n",
    "        reader = csv.DictReader(f, delimiter='\\t', fieldnames=['timestamp', 'user_id', 'item_id', 'session_id'])\n",
    "    else:\n",
    "        reader = csv.DictReader(f, delimiter=';', fieldnames=['session_id', 'user_id', 'item_id', 'timestamp', 'eventdate'])\n",
    "        next(reader)\n",
    "    sess_clicks = {}\n",
    "    sess_date = {}\n",
    "    ctr = 0\n",
    "    curid = -1\n",
    "    curdate = None\n",
    "    isfirstline = 1\n",
    "    for data in reader:\n",
    "        if isfirstline and opt.dataset == 'retailrocket':\n",
    "            isfirstline = 0\n",
    "            continue\n",
    "        sessid = data['session_id']\n",
    "        if curdate and not curid == sessid:\n",
    "            date = ''\n",
    "            if opt.dataset == 'retailrocket':\n",
    "                date = int(curdate)\n",
    "            else:\n",
    "                date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
    "            sess_date[curid] = date\n",
    "        curid = sessid\n",
    "        if opt.dataset == 'retailrocket':\n",
    "            item = data['item_id']\n",
    "        else:\n",
    "            item = data['item_id']\n",
    "        curdate = ''\n",
    "        if  opt.dataset == 'retailrocket':\n",
    "            curdate = data['timestamp']\n",
    "        else:\n",
    "            curdate = data['eventdate']\n",
    "\n",
    "        if sessid in sess_clicks:\n",
    "            sess_clicks[sessid] += [item]\n",
    "        else:\n",
    "            sess_clicks[sessid] = [item]\n",
    "        ctr += 1\n",
    "    date = ''\n",
    "    if opt.dataset == 'retailrocket':\n",
    "        date = int(curdate)\n",
    "    else:\n",
    "        date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
    "    sess_date[curid] = date\n",
    "print(\"-- Reading data @ %ss\" % datetime.datetime.now())\n",
    "\n",
    "# Filter out length 1 sessions\n",
    "for s in list(sess_clicks):\n",
    "    if len(sess_clicks[s]) <= 2:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "\n",
    "# Count number of times each item appears\n",
    "iid_counts = {}\n",
    "for s in sess_clicks:\n",
    "    seq = sess_clicks[s]\n",
    "    for iid in seq:\n",
    "        if iid in iid_counts:\n",
    "            iid_counts[iid] += 1\n",
    "        else:\n",
    "            iid_counts[iid] = 1\n",
    "\n",
    "sorted_counts = sorted(iid_counts.items(), key=operator.itemgetter(1))\n",
    "length = len(sess_clicks)\n",
    "max_len = 3\n",
    "for s in list(sess_clicks):\n",
    "    curseq = sess_clicks[s]\n",
    "    filseq = list(filter(lambda i: iid_counts[i] >= 5, curseq))\n",
    "    if len(filseq) < max_len:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "    else:\n",
    "        sess_clicks[s] = filseq\n",
    "\n",
    "# Split out test set based on dates\n",
    "dates = list(sess_date.items())\n",
    "maxdate = dates[0][1]\n",
    "\n",
    "for _, date in dates:\n",
    "    if maxdate < date:\n",
    "        maxdate = date\n",
    "\n",
    "# 7 days for test\n",
    "splitdate = maxdate - 86400 * 7\n",
    "\n",
    "print('Splitting date', splitdate)      \n",
    "tra_sess = filter(lambda x: x[1] < splitdate, dates)\n",
    "tes_sess = filter(lambda x: x[1] > splitdate, dates)\n",
    "\n",
    "# Sort sessions by date\n",
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))\n",
    "print(\"Train Session Length:\", len(tra_sess))\n",
    "print(\"Test Session Length:\", len(tes_sess))\n",
    "print(tra_sess[:3])\n",
    "print(tes_sess[:3])\n",
    "print(\"-- Splitting train set and test set @ %ss\" % datetime.datetime.now())\n",
    "\n",
    "# Choosing item count >=5 gives approximately the same number of items as reported in paper\n",
    "item_dict = {}\n",
    "# Convert training sessions to sequences and renumber items to start from 1\n",
    "def obtian_tra():\n",
    "    train_ids = []\n",
    "    train_seqs = []\n",
    "    train_dates = []\n",
    "    item_ctr = 1\n",
    "    for s, date in tra_sess:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        if len(seq) < max_len:\n",
    "            continue\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "            else:\n",
    "                outseq += [item_ctr]\n",
    "                item_dict[i] = item_ctr\n",
    "                item_ctr += 1\n",
    "\n",
    "        train_ids += [s]\n",
    "        train_dates += [date]\n",
    "        train_seqs += [outseq]\n",
    "    print('obtain_tra-------item_num=', item_ctr)\n",
    "    return train_ids, train_dates, train_seqs\n",
    "\n",
    "\n",
    "# Convert test sessions to sequences, ignoring items that do not appear in training set\n",
    "def obtian_tes():\n",
    "    test_ids = []\n",
    "    test_seqs = []\n",
    "    test_dates = []\n",
    "    for s, date in tes_sess:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "        if len(outseq) < max_len:\n",
    "            continue\n",
    "        test_ids += [s]\n",
    "        test_dates += [date]\n",
    "        test_seqs += [outseq]\n",
    "    return test_ids, test_dates, test_seqs\n",
    "\n",
    "\n",
    "tra_ids, tra_dates, tra_seqs = obtian_tra()\n",
    "tes_ids, tes_dates, tes_seqs = obtian_tes()\n",
    "\n",
    "def process_seqs(tra_ids, iseqs, idates):\n",
    "    out_seqs = []\n",
    "    out_dates = []\n",
    "    labs = []\n",
    "    ids = []\n",
    "    for id, seq, date in zip(tra_ids, iseqs, idates):\n",
    "        for i in range(1, len(seq) - 1):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [seq[:-i]]\n",
    "            out_dates += [int(date)]\n",
    "            ids += [int(id)]\n",
    "    return out_seqs, out_dates, labs, ids\n",
    "\n",
    "\n",
    "tr_seqs, tr_dates, tr_labs, tr_ids = process_seqs(tra_ids, tra_seqs, tra_dates)\n",
    "te_seqs, te_dates, te_labs, te_ids = process_seqs(tes_ids, tes_seqs, tes_dates)\n",
    "tra = (tr_ids, tr_seqs, tr_labs, tr_dates)\n",
    "tes = (te_ids, te_seqs, te_labs, te_dates)\n",
    "all_train_seq = (tra_ids, tra_seqs)\n",
    "\n",
    "\n",
    "print('training sessions = ', len(tr_seqs))\n",
    "print('testing sessions = ', len(te_seqs))\n",
    "print(tr_seqs[:3], tr_dates[:3], tr_labs[:3])\n",
    "print(te_seqs[:3], te_dates[:3], te_labs[:3])\n",
    "all = 0\n",
    "\n",
    "for seq in tra_seqs:\n",
    "    all += len(seq)\n",
    "for seq in tes_seqs:\n",
    "    all += len(seq)\n",
    "print('all clicks: ', all)\n",
    "print('avg length: ', all / (len(tra_seqs) + len(tes_seqs) * 1.0))\n",
    "if opt.dataset == 'diginetica':\n",
    "    pickle.dump(tra, open('./data/diginetica/train.txt', 'wb'))\n",
    "    pickle.dump(tes, open('./data/diginetica/test.txt', 'wb'))\n",
    "    pickle.dump(all_train_seq, open('./data/diginetica/all_train_seq.txt', 'wb'))\n",
    "elif opt.dataset == 'retailrocket':\n",
    "    pickle.dump(tra, open('./data/retailrocket/train.txt', 'wb'))\n",
    "    pickle.dump(tes, open('./data/retailrocket/test.txt', 'wb'))\n",
    "    pickle.dump(all_train_seq, open('./data/retailrocket/all_train_seq.txt', 'wb'))\n",
    "else:\n",
    "    if not os.path.exists('sample'):\n",
    "        os.makedirs('sample')\n",
    "    pickle.dump(tra, open('sample/train.txt', 'wb'))\n",
    "    pickle.dump(tes, open('sample/test.txt', 'wb'))\n",
    "    pickle.dump(all_train_seq, open('sample/all_train_seq.txt', 'wb'))\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "yjh",
   "language": "python",
   "display_name": "yjh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}