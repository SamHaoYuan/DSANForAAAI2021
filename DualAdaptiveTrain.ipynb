{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import math\n",
    "from metric import get_mrr, get_recall\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import pickle\n",
    "from entmax import  entmax_bisect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "test64 = pickle.load(open('data/diginetica/test.txt', 'rb'))\n",
    "train64 = pickle.load(open('data/diginetica/train.txt', 'rb'))\n",
    "\n",
    "train64_x = train64[1]\n",
    "train64_y = train64[2]\n",
    "\n",
    "test64_x = test64[1]\n",
    "test64_y = test64[2]\n",
    "train_pos = list()\n",
    "test_pos = list()\n",
    "\n",
    "item_set = set()\n",
    "item_set = set()\n",
    "\n",
    "for items in train64[1]:\n",
    "    pos = list()\n",
    "    for id_ in range(len(items)):\n",
    "        item_set.add(items[id_])\n",
    "        pos.append(id_ + 1)\n",
    "    pos.append(len(items)+1)\n",
    "    train_pos.append(pos)\n",
    "\n",
    "for item in train64[2]:\n",
    "    item_set.add(item)\n",
    "\n",
    "for items in test64[1]:\n",
    "    pos = []\n",
    "    for id_ in range(len(items)):\n",
    "        item_set.add(items[id_])\n",
    "        pos.append(id_ + 1)\n",
    "    pos.append(len(items)+1)\n",
    "    test_pos.append(pos)\n",
    "    \n",
    "for item in test64[2]:\n",
    "    item_set.add(item)\n",
    "item_list = sorted(list(item_set))\n",
    "item_dict = dict()\n",
    "for i in range(1, len(item_set)+1):\n",
    "    item = item_list[i-1]\n",
    "    item_dict[item] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train64_x = list()\n",
    "train64_y = list()\n",
    "\n",
    "test64_x = list()\n",
    "test64_y = list()\n",
    "    \n",
    "for items in train64[1]:\n",
    "    new_list = []\n",
    "    for item in items:\n",
    "        new_item = item_dict[item]\n",
    "        new_list.append(new_item)\n",
    "    train64_x.append(new_list)\n",
    "for item in train64[2]:\n",
    "    new_item = item_dict[item]\n",
    "    train64_y.append(new_item)\n",
    "for items in test64[1]:\n",
    "    new_list = []\n",
    "    for item in items:\n",
    "        new_item = item_dict[item]\n",
    "        new_list.append(new_item)\n",
    "    test64_x.append(new_list)\n",
    "for item in test64[2]:\n",
    "    new_item = item_dict[item]\n",
    "    test64_y.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for sample in train64_x:\n",
    "    max_length = len(sample) if len(sample) > max_length else max_length\n",
    "for sample in test64_x:\n",
    "    max_length = len(sample) if len(sample) > max_length else max_length \n",
    "\n",
    "train_seqs = np.zeros((len(train64_x), max_length))\n",
    "train_poses = np.zeros((len(train64_x), max_length+1))\n",
    "test_seqs = np.zeros((len(test64_x), max_length))\n",
    "test_poses = np.zeros((len(test64_x), max_length+1))\n",
    "\n",
    "for i in range(len(train64_x)):\n",
    "    seq = train64_x[i]\n",
    "    pos = train_pos[i]\n",
    "    length = len(seq)\n",
    "    train_seqs[i][-length:] = seq\n",
    "    train_poses[i][-length-1:] = pos\n",
    "    \n",
    "for i in range(len(test64_x)):\n",
    "    seq = test64_x[i]\n",
    "    pos = test_pos[i]\n",
    "    length = len(seq)\n",
    "    test_seqs[i][-length:] = seq\n",
    "    test_poses[i][-length-1:] = pos\n",
    "\n",
    "target_seqs = np.array(train64_y)\n",
    "target_test_seqs = np.array(test64_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_set = set()\n",
    "for items in train64_x:\n",
    "    for item in items:\n",
    "        item_set.add(item)\n",
    "for item in train64_y:\n",
    "    item_set.add(item)\n",
    "for items in test64_x:\n",
    "    for item in items:\n",
    "        item_set.add(item)\n",
    "for item in test64_y:\n",
    "    item_set.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_seqs)\n",
    "train_pos = torch.Tensor(train_poses)\n",
    "train_y = torch.Tensor(target_seqs)\n",
    "test_x = torch.Tensor(test_seqs)\n",
    "test_pos = torch.Tensor(test_poses)\n",
    "test_y = torch.Tensor(target_test_seqs)\n",
    "train_label = torch.Tensor([40841]).repeat(len(train64_x)).unsqueeze(1)\n",
    "test_label = torch.Tensor([40841]).repeat(len(test64_x)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.cat((train_x, train_label), 1)\n",
    "test_x = torch.cat((test_x, test_label), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DualAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, item_dim, pos_dim, n_items, n_pos, w, atten_way='dot', decoder_way='bilinear', dropout=0,\n",
    "                 activate='relu'):\n",
    "        super(DualAttention, self).__init__()\n",
    "        self.item_dim = item_dim\n",
    "        self.pos_dim = pos_dim\n",
    "        dim = item_dim + pos_dim\n",
    "        self.dim = dim\n",
    "        self.n_items = n_items\n",
    "        self.embedding = nn.Embedding(n_items + 1, item_dim, padding_idx=0,max_norm=1.5)\n",
    "        self.pos_embedding = nn.Embedding(n_pos, pos_dim, padding_idx=0, max_norm=1.5)\n",
    "        self.atten_way = atten_way\n",
    "        self.decoder_way = decoder_way\n",
    "        self.atten_w0 = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.atten_w1 = nn.Parameter(torch.Tensor(dim, dim))\n",
    "        self.atten_w2 = nn.Parameter(torch.Tensor(dim, dim))\n",
    "        self.atten_bias = nn.Parameter(torch.Tensor(dim))\n",
    "        self.w_f = nn.Linear(2*dim, item_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.self_atten_w1 = nn.Linear(dim, dim)\n",
    "        self.self_atten_w2 = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.LN = nn.LayerNorm(dim)\n",
    "        self.LN2 = nn.LayerNorm(item_dim)\n",
    "        self.is_dropout = True\n",
    "        self.attention_mlp = nn.Linear(dim, dim)\n",
    "        self.alpha_w = nn.Linear(dim, 1)\n",
    "        self.w = w\n",
    "        \n",
    "        if activate == 'relu':\n",
    "            self.activate = F.relu\n",
    "        elif activate == 'selu':\n",
    "            self.activate = F.selu\n",
    "\n",
    "        self.initial_()\n",
    "\n",
    "    def initial_(self):\n",
    "        \n",
    "        init.normal_(self.atten_w0, 0, 0.05)\n",
    "        init.normal_(self.atten_w1, 0, 0.05)\n",
    "        init.normal_(self.atten_w2, 0, 0.05)\n",
    "        init.constant_(self.atten_bias, 0)\n",
    "        init.constant_(self.attention_mlp.bias, 0)\n",
    "        init.constant_(self.embedding.weight[0], 0)\n",
    "        init.constant_(self.pos_embedding.weight[0], 0)\n",
    "\n",
    "    def forward(self, x, pos):\n",
    "        self.is_dropout = True\n",
    "        x_embeddings = self.embedding(x)  # B,seq,dim\n",
    "        pos_embeddings = self.pos_embedding(pos)  # B, seq, dim \n",
    "        mask = (x != 0).float()  # B,seq\n",
    "        x_ = torch.cat((x_embeddings, pos_embeddings), 2)  # B seq, 2*dim\n",
    "        x_s = x_[:, :-1, :]  # B, seq-1, 2*dim\n",
    "        alpha_ent = self.get_alpha(x = x_[:, -1, :], number= 0)\n",
    "        m_s, x_n = self.self_attention(x_, x_, x_, mask, alpha_ent)\n",
    "        alpha_global = self.get_alpha(x= m_s, number=1)\n",
    "        global_c = self.global_attention(m_s, x_n, x_s, mask, alpha_global)  # B, 1, dim\n",
    "        h_t = global_c\n",
    "        result = self.decoder(h_t, m_s)\n",
    "        return result\n",
    "    \n",
    "    def get_alpha(self, x=None, number=None):\n",
    "        if number == 0:\n",
    "            alpha_ent = torch.sigmoid(self.alpha_w(x)) + 1\n",
    "            alpha_ent = self.add_value(alpha_ent).unsqueeze(1)\n",
    "            alpha_ent = alpha_ent.expand(-1, 70, -1)\n",
    "            return alpha_ent\n",
    "        if number == 1:\n",
    "            alpha_global = torch.sigmoid(self.alpha_w(x)) + 1\n",
    "            alpha_global = self.add_value(alpha_global)\n",
    "            return alpha_global\n",
    "\n",
    "    def add_value(self, value):\n",
    "\n",
    "        mask_value = (value ==1).float()\n",
    "        value = value.masked_fill(mask_value == 1, 1.00001)\n",
    "        return value\n",
    "        \n",
    "    def self_attention(self, q, k, v, mask=None, alpha_ent = 1):\n",
    "\n",
    "        if self.is_dropout:\n",
    "            q_ = self.dropout(self.activate(self.attention_mlp(q)))\n",
    "        else:\n",
    "            q_ = self.activate(self.attention_mlp(q))\n",
    "        scores = torch.matmul(q_, k.transpose(1, 2)) / math.sqrt(self.dim)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand(-1, q.size(1), -1)\n",
    "            scores = scores.masked_fill(mask == 0, -np.inf)      \n",
    "        alpha = entmax_bisect(scores, alpha_ent, dim=-1)\n",
    "\n",
    "        att_v = torch.matmul(alpha, v)  # B, seq, dim\n",
    "        if self.is_dropout:\n",
    "            att_v = self.dropout(self.self_atten_w2(self.activate(self.self_atten_w1(att_v)))) + att_v\n",
    "        else:\n",
    "            att_v = self.self_atten_w2(self.activate(self.self_atten_w1(att_v))) + att_v\n",
    "        att_v = self.LN(att_v)\n",
    "        c = att_v[:, -1, :].unsqueeze(1)\n",
    "        x_n = att_v[:, :-1, :]\n",
    "        return c, x_n\n",
    "\n",
    "    def global_attention(self,target,k, v, mask=None, alpha_ent=1):\n",
    "        alpha = torch.matmul(\n",
    "            torch.relu(k.matmul(self.atten_w1) + target.matmul(self.atten_w2) + self.atten_bias),\n",
    "            self.atten_w0.t())  # (B,seq,1)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(-1)\n",
    "            mask = mask[:, :-1, :]\n",
    "            alpha = alpha.masked_fill(mask == 0, -np.inf)\n",
    "        alpha = entmax_bisect(alpha, alpha_ent, dim=1)\n",
    "        c = torch.matmul(alpha.transpose(1, 2), v)  # (B, 1, dim)\n",
    "        return c\n",
    "\n",
    "    def decoder(self, global_c, self_c):\n",
    "        if self.is_dropout:\n",
    "            c = self.dropout(torch.selu(self.w_f(torch.cat((global_c, self_c), 2))))\n",
    "        else:\n",
    "            c = torch.selu(self.w_f(torch.cat((global_c, self_c), 2)))\n",
    "        c = c.squeeze()\n",
    "        l_c = (c/torch.norm(c, dim=-1).unsqueeze(1))\n",
    "        l_emb = self.embedding.weight[1:-1]/torch.norm(self.embedding.weight[1:-1], dim=-1).unsqueeze(1)\n",
    "        z = self.w * torch.matmul(l_c, l_emb.t())\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "    def predict(self, x, pos, k=20):\n",
    "        self.is_dropout = False\n",
    "        x_embeddings = self.embedding(x)  # B,seq,dim\n",
    "        pos_embeddings = self.pos_embedding(pos)  # B, seq, dim\n",
    "        mask = (x != 0).float()  # B,seq\n",
    "        x_ = torch.cat((x_embeddings, pos_embeddings), 2)  # B seq, 2*dim\n",
    "        x_s = x_[:, :-1, :]  # B, seq-1, 2*dim\n",
    "        alpha_ent = self.get_alpha(x = x_[:, -1, :], number= 0)\n",
    "        m_s, x_n = self.self_attention(x_, x_, x_, mask, alpha_ent)\n",
    "        alpha_global = self.get_alpha(x= m_s, number=1)\n",
    "        global_c = self.global_attention(m_s, x_n, x_s, mask, alpha_global)  # B, 1, dim\n",
    "        h_t = global_c\n",
    "        result = self.decoder(h_t, m_s)\n",
    "        rank = torch.argsort(result, dim=1, descending=True)\n",
    "        return rank[:, 0:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2020-09-14 14:03:02\n",
      "[00/50] [099/1027] mean_loss : 13.13\n",
      "[00/50] [199/1027] mean_loss : 12.52\n",
      "[00/50] [299/1027] mean_loss : 12.05\n",
      "[00/50] [399/1027] mean_loss : 11.73\n",
      "[00/50] [499/1027] mean_loss : 11.51\n",
      "[00/50] [599/1027] mean_loss : 11.33\n",
      "[00/50] [699/1027] mean_loss : 11.19\n",
      "[00/50] [799/1027] mean_loss : 11.06\n",
      "[00/50] [899/1027] mean_loss : 10.94\n",
      "[00/50] [999/1027] mean_loss : 10.82\n",
      "Recall@20: 0.3212 Recall@10: 0.2958  Recall@5:0.2691\n",
      "MRR@20:0.2388 MRR@10:0.2370 MRR@5:0.2334\n",
      "best result: 0.3212132161972944\n",
      "==================================\n",
      "2020-09-14 14:03:58\n",
      "[01/50] [099/1027] mean_loss : 9.31\n",
      "[01/50] [199/1027] mean_loss : 9.19\n",
      "[01/50] [299/1027] mean_loss : 9.10\n",
      "[01/50] [399/1027] mean_loss : 9.01\n",
      "[01/50] [499/1027] mean_loss : 8.93\n",
      "[01/50] [599/1027] mean_loss : 8.85\n",
      "[01/50] [699/1027] mean_loss : 8.78\n",
      "[01/50] [799/1027] mean_loss : 8.71\n",
      "[01/50] [899/1027] mean_loss : 8.64\n",
      "[01/50] [999/1027] mean_loss : 8.57\n",
      "Recall@20: 0.4697 Recall@10: 0.4082  Recall@5:0.3443\n",
      "MRR@20:0.2709 MRR@10:0.2666 MRR@5:0.2581\n",
      "best result: 0.46974863930983085\n",
      "==================================\n",
      "2020-09-14 14:04:55\n",
      "[02/50] [099/1027] mean_loss : 7.51\n",
      "[02/50] [199/1027] mean_loss : 7.46\n",
      "[02/50] [299/1027] mean_loss : 7.41\n",
      "[02/50] [399/1027] mean_loss : 7.37\n",
      "[02/50] [499/1027] mean_loss : 7.34\n",
      "[02/50] [599/1027] mean_loss : 7.30\n",
      "[02/50] [699/1027] mean_loss : 7.27\n",
      "[02/50] [799/1027] mean_loss : 7.23\n",
      "[02/50] [899/1027] mean_loss : 7.20\n",
      "[02/50] [999/1027] mean_loss : 7.17\n",
      "Recall@20: 0.5432 Recall@10: 0.4635  Recall@5:0.3842\n",
      "MRR@20:0.2896 MRR@10:0.2841 MRR@5:0.2734\n",
      "best result: 0.5432372004787822\n",
      "==================================\n",
      "2020-09-14 14:05:53\n",
      "[03/50] [099/1027] mean_loss : 6.55\n",
      "[03/50] [199/1027] mean_loss : 6.52\n",
      "[03/50] [299/1027] mean_loss : 6.50\n",
      "[03/50] [399/1027] mean_loss : 6.49\n",
      "[03/50] [499/1027] mean_loss : 6.47\n",
      "[03/50] [599/1027] mean_loss : 6.46\n",
      "[03/50] [699/1027] mean_loss : 6.44\n",
      "[03/50] [799/1027] mean_loss : 6.42\n",
      "[03/50] [899/1027] mean_loss : 6.41\n",
      "[03/50] [999/1027] mean_loss : 6.40\n",
      "Recall@20: 0.5833 Recall@10: 0.4943  Recall@5:0.4057\n",
      "MRR@20:0.3013 MRR@10:0.2952 MRR@5:0.2833\n",
      "best result: 0.5833465073736986\n",
      "==================================\n",
      "2020-09-14 14:07:02\n",
      "[04/50] [099/1027] mean_loss : 6.03\n",
      "[04/50] [199/1027] mean_loss : 6.00\n",
      "[04/50] [299/1027] mean_loss : 5.98\n",
      "[04/50] [399/1027] mean_loss : 5.97\n",
      "[04/50] [499/1027] mean_loss : 5.97\n",
      "[04/50] [599/1027] mean_loss : 5.97\n",
      "[04/50] [699/1027] mean_loss : 5.96\n",
      "[04/50] [799/1027] mean_loss : 5.95\n",
      "[04/50] [899/1027] mean_loss : 5.95\n",
      "[04/50] [999/1027] mean_loss : 5.94\n",
      "Recall@20: 0.6070 Recall@10: 0.5143  Recall@5:0.4198\n",
      "MRR@20:0.3088 MRR@10:0.3024 MRR@5:0.2898\n",
      "best result: 0.6070146118927708\n",
      "==================================\n",
      "2020-09-14 14:08:00\n",
      "[05/50] [099/1027] mean_loss : 5.70\n",
      "[05/50] [199/1027] mean_loss : 5.66\n",
      "[05/50] [299/1027] mean_loss : 5.65\n",
      "[05/50] [399/1027] mean_loss : 5.65\n",
      "[05/50] [499/1027] mean_loss : 5.65\n",
      "[05/50] [599/1027] mean_loss : 5.65\n",
      "[05/50] [699/1027] mean_loss : 5.65\n",
      "[05/50] [799/1027] mean_loss : 5.65\n",
      "[05/50] [899/1027] mean_loss : 5.65\n",
      "[05/50] [999/1027] mean_loss : 5.65\n",
      "Recall@20: 0.6230 Recall@10: 0.5268  Recall@5:0.4308\n",
      "MRR@20:0.3136 MRR@10:0.3069 MRR@5:0.2941\n",
      "best result: 0.622958964746268\n",
      "==================================\n",
      "2020-09-14 14:08:57\n",
      "[06/50] [099/1027] mean_loss : 5.44\n",
      "[06/50] [199/1027] mean_loss : 5.43\n",
      "[06/50] [299/1027] mean_loss : 5.43\n",
      "[06/50] [399/1027] mean_loss : 5.43\n",
      "[06/50] [499/1027] mean_loss : 5.44\n",
      "[06/50] [599/1027] mean_loss : 5.44\n",
      "[06/50] [699/1027] mean_loss : 5.44\n",
      "[06/50] [799/1027] mean_loss : 5.45\n",
      "[06/50] [899/1027] mean_loss : 5.45\n",
      "[06/50] [999/1027] mean_loss : 5.45\n",
      "Recall@20: 0.6341 Recall@10: 0.5360  Recall@5:0.4373\n",
      "MRR@20:0.3176 MRR@10:0.3107 MRR@5:0.2975\n",
      "best result: 0.6341154949298765\n",
      "==================================\n",
      "2020-09-14 14:09:55\n",
      "[07/50] [099/1027] mean_loss : 5.31\n",
      "[07/50] [199/1027] mean_loss : 5.27\n",
      "[07/50] [299/1027] mean_loss : 5.28\n",
      "[07/50] [399/1027] mean_loss : 5.28\n",
      "[07/50] [499/1027] mean_loss : 5.28\n",
      "[07/50] [599/1027] mean_loss : 5.29\n",
      "[07/50] [699/1027] mean_loss : 5.29\n",
      "[07/50] [799/1027] mean_loss : 5.29\n",
      "[07/50] [899/1027] mean_loss : 5.30\n",
      "[07/50] [999/1027] mean_loss : 5.30\n",
      "Recall@20: 0.6428 Recall@10: 0.5451  Recall@5:0.4434\n",
      "MRR@20:0.3199 MRR@10:0.3131 MRR@5:0.2995\n",
      "best result: 0.6427651934325527\n",
      "==================================\n",
      "2020-09-14 14:11:03\n",
      "[08/50] [099/1027] mean_loss : 5.16\n",
      "[08/50] [199/1027] mean_loss : 5.15\n",
      "[08/50] [299/1027] mean_loss : 5.16\n",
      "[08/50] [399/1027] mean_loss : 5.16\n",
      "[08/50] [499/1027] mean_loss : 5.16\n",
      "[08/50] [599/1027] mean_loss : 5.17\n",
      "[08/50] [699/1027] mean_loss : 5.18\n",
      "[08/50] [799/1027] mean_loss : 5.18\n",
      "[08/50] [899/1027] mean_loss : 5.18\n",
      "[08/50] [999/1027] mean_loss : 5.19\n",
      "Recall@20: 0.6498 Recall@10: 0.5505  Recall@5:0.4479\n",
      "MRR@20:0.3225 MRR@10:0.3156 MRR@5:0.3019\n",
      "best result: 0.6498114230222002\n",
      "==================================\n",
      "2020-09-14 14:13:16\n",
      "[09/50] [099/1027] mean_loss : 5.06\n",
      "[09/50] [199/1027] mean_loss : 5.05\n",
      "[09/50] [299/1027] mean_loss : 5.05\n",
      "[09/50] [399/1027] mean_loss : 5.06\n",
      "[09/50] [499/1027] mean_loss : 5.07\n",
      "[09/50] [599/1027] mean_loss : 5.08\n",
      "[09/50] [699/1027] mean_loss : 5.09\n",
      "[09/50] [799/1027] mean_loss : 5.09\n",
      "[09/50] [899/1027] mean_loss : 5.10\n",
      "[09/50] [999/1027] mean_loss : 5.10\n",
      "Recall@20: 0.6555 Recall@10: 0.5547  Recall@5:0.4514\n",
      "MRR@20:0.3230 MRR@10:0.3160 MRR@5:0.3022\n",
      "best result: 0.6555477765983875\n",
      "==================================\n",
      "2020-09-14 14:15:29\n",
      "[10/50] [099/1027] mean_loss : 4.99\n",
      "[10/50] [199/1027] mean_loss : 4.98\n",
      "[10/50] [299/1027] mean_loss : 4.99\n",
      "[10/50] [399/1027] mean_loss : 4.99\n",
      "[10/50] [499/1027] mean_loss : 5.00\n",
      "[10/50] [599/1027] mean_loss : 5.01\n",
      "[10/50] [699/1027] mean_loss : 5.01\n",
      "[10/50] [799/1027] mean_loss : 5.02\n",
      "[10/50] [899/1027] mean_loss : 5.03\n",
      "[10/50] [999/1027] mean_loss : 5.03\n",
      "Recall@20: 0.6584 Recall@10: 0.5589  Recall@5:0.4530\n",
      "MRR@20:0.3243 MRR@10:0.3174 MRR@5:0.3032\n",
      "best result: 0.6583933693172835\n",
      "==================================\n",
      "2020-09-14 14:17:43\n",
      "[11/50] [099/1027] mean_loss : 4.92\n",
      "[11/50] [199/1027] mean_loss : 4.91\n",
      "[11/50] [299/1027] mean_loss : 4.92\n",
      "[11/50] [399/1027] mean_loss : 4.93\n",
      "[11/50] [499/1027] mean_loss : 4.94\n",
      "[11/50] [599/1027] mean_loss : 4.95\n",
      "[11/50] [699/1027] mean_loss : 4.95\n",
      "[11/50] [799/1027] mean_loss : 4.96\n",
      "[11/50] [899/1027] mean_loss : 4.97\n",
      "[11/50] [999/1027] mean_loss : 4.97\n",
      "Recall@20: 0.6631 Recall@10: 0.5629  Recall@5:0.4568\n",
      "MRR@20:0.3260 MRR@10:0.3190 MRR@5:0.3048\n",
      "best result: 0.6630682716411843\n",
      "==================================\n",
      "2020-09-14 14:19:57\n",
      "[12/50] [099/1027] mean_loss : 4.88\n",
      "[12/50] [199/1027] mean_loss : 4.87\n",
      "[12/50] [299/1027] mean_loss : 4.87\n",
      "[12/50] [399/1027] mean_loss : 4.88\n",
      "[12/50] [499/1027] mean_loss : 4.89\n",
      "[12/50] [599/1027] mean_loss : 4.90\n",
      "[12/50] [699/1027] mean_loss : 4.90\n",
      "[12/50] [799/1027] mean_loss : 4.91\n",
      "[12/50] [899/1027] mean_loss : 4.91\n",
      "[12/50] [999/1027] mean_loss : 4.92\n",
      "Recall@20: 0.6652 Recall@10: 0.5638  Recall@5:0.4575\n",
      "MRR@20:0.3249 MRR@10:0.3178 MRR@5:0.3035\n",
      "best result: 0.6651911741457576\n",
      "==================================\n",
      "2020-09-14 14:22:12\n",
      "[13/50] [099/1027] mean_loss : 4.82\n",
      "[13/50] [199/1027] mean_loss : 4.82\n",
      "[13/50] [299/1027] mean_loss : 4.83\n",
      "[13/50] [399/1027] mean_loss : 4.83\n",
      "[13/50] [499/1027] mean_loss : 4.84\n",
      "[13/50] [599/1027] mean_loss : 4.85\n",
      "[13/50] [699/1027] mean_loss : 4.86\n",
      "[13/50] [799/1027] mean_loss : 4.86\n",
      "[13/50] [899/1027] mean_loss : 4.87\n",
      "[13/50] [999/1027] mean_loss : 4.88\n",
      "Recall@20: 0.6689 Recall@10: 0.5665  Recall@5:0.4603\n",
      "MRR@20:0.3264 MRR@10:0.3193 MRR@5:0.3050\n",
      "best result: 0.6689401296325572\n",
      "==================================\n",
      "2020-09-14 14:24:27\n",
      "[14/50] [099/1027] mean_loss : 4.80\n",
      "[14/50] [199/1027] mean_loss : 4.79\n",
      "[14/50] [299/1027] mean_loss : 4.79\n",
      "[14/50] [399/1027] mean_loss : 4.79\n",
      "[14/50] [499/1027] mean_loss : 4.80\n",
      "[14/50] [599/1027] mean_loss : 4.81\n",
      "[14/50] [699/1027] mean_loss : 4.82\n",
      "[14/50] [799/1027] mean_loss : 4.82\n",
      "[14/50] [899/1027] mean_loss : 4.83\n",
      "[14/50] [999/1027] mean_loss : 4.84\n",
      "Recall@20: 0.6713 Recall@10: 0.5680  Recall@5:0.4609\n",
      "MRR@20:0.3263 MRR@10:0.3191 MRR@5:0.3047\n",
      "best result: 0.6712888728291063\n",
      "==================================\n",
      "2020-09-14 14:26:41\n",
      "[15/50] [099/1027] mean_loss : 4.75\n",
      "[15/50] [199/1027] mean_loss : 4.75\n",
      "[15/50] [299/1027] mean_loss : 4.75\n",
      "[15/50] [399/1027] mean_loss : 4.76\n",
      "[15/50] [499/1027] mean_loss : 4.77\n",
      "[15/50] [599/1027] mean_loss : 4.78\n",
      "[15/50] [699/1027] mean_loss : 4.79\n",
      "[15/50] [799/1027] mean_loss : 4.80\n",
      "[15/50] [899/1027] mean_loss : 4.81\n",
      "[15/50] [999/1027] mean_loss : 4.81\n",
      "Recall@20: 0.6733 Recall@10: 0.5702  Recall@5:0.4617\n",
      "MRR@20:0.3264 MRR@10:0.3192 MRR@5:0.3047\n",
      "best result: 0.6732988549876917\n",
      "==================================\n",
      "2020-09-14 14:28:57\n",
      "[16/50] [099/1027] mean_loss : 4.74\n",
      "[16/50] [199/1027] mean_loss : 4.73\n",
      "[16/50] [299/1027] mean_loss : 4.73\n",
      "[16/50] [399/1027] mean_loss : 4.74\n",
      "[16/50] [499/1027] mean_loss : 4.75\n",
      "[16/50] [599/1027] mean_loss : 4.75\n",
      "[16/50] [699/1027] mean_loss : 4.76\n",
      "[16/50] [799/1027] mean_loss : 4.77\n",
      "[16/50] [899/1027] mean_loss : 4.77\n",
      "[16/50] [999/1027] mean_loss : 4.78\n",
      "Recall@20: 0.6743 Recall@10: 0.5716  Recall@5:0.4634\n",
      "MRR@20:0.3268 MRR@10:0.3196 MRR@5:0.3051\n",
      "best result: 0.6742925540323855\n",
      "==================================\n",
      "2020-09-14 14:31:12\n",
      "[17/50] [099/1027] mean_loss : 4.70\n",
      "[17/50] [199/1027] mean_loss : 4.70\n",
      "[17/50] [299/1027] mean_loss : 4.70\n",
      "[17/50] [399/1027] mean_loss : 4.71\n",
      "[17/50] [499/1027] mean_loss : 4.72\n",
      "[17/50] [599/1027] mean_loss : 4.73\n",
      "[17/50] [699/1027] mean_loss : 4.73\n",
      "[17/50] [799/1027] mean_loss : 4.74\n",
      "[17/50] [899/1027] mean_loss : 4.75\n",
      "[17/50] [999/1027] mean_loss : 4.76\n",
      "Recall@20: 0.6764 Recall@10: 0.5725  Recall@5:0.4637\n",
      "MRR@20:0.3268 MRR@10:0.3195 MRR@5:0.3049\n",
      "best result: 0.6763928724677613\n",
      "==================================\n",
      "2020-09-14 14:33:27\n",
      "[18/50] [099/1027] mean_loss : 4.68\n",
      "[18/50] [199/1027] mean_loss : 4.68\n",
      "[18/50] [299/1027] mean_loss : 4.68\n",
      "[18/50] [399/1027] mean_loss : 4.69\n",
      "[18/50] [499/1027] mean_loss : 4.69\n",
      "[18/50] [599/1027] mean_loss : 4.70\n",
      "[18/50] [699/1027] mean_loss : 4.71\n",
      "[18/50] [799/1027] mean_loss : 4.72\n",
      "[18/50] [899/1027] mean_loss : 4.73\n",
      "[18/50] [999/1027] mean_loss : 4.73\n",
      "Recall@20: 0.6764 Recall@10: 0.5743  Recall@5:0.4655\n",
      "MRR@20:0.3274 MRR@10:0.3202 MRR@5:0.3057\n",
      "best result: 0.6764154565369588\n",
      "==================================\n",
      "2020-09-14 14:35:43\n",
      "[19/50] [099/1027] mean_loss : 4.66\n",
      "[19/50] [199/1027] mean_loss : 4.65\n",
      "[19/50] [299/1027] mean_loss : 4.66\n",
      "[19/50] [399/1027] mean_loss : 4.66\n",
      "[19/50] [499/1027] mean_loss : 4.67\n",
      "[19/50] [599/1027] mean_loss : 4.68\n",
      "[19/50] [699/1027] mean_loss : 4.69\n",
      "[19/50] [799/1027] mean_loss : 4.70\n",
      "[19/50] [899/1027] mean_loss : 4.71\n",
      "[19/50] [999/1027] mean_loss : 4.72\n",
      "Recall@20: 0.6783 Recall@10: 0.5743  Recall@5:0.4654\n",
      "MRR@20:0.3272 MRR@10:0.3200 MRR@5:0.3054\n",
      "best result: 0.6782899342803587\n",
      "==================================\n",
      "2020-09-14 14:37:58\n",
      "[20/50] [099/1027] mean_loss : 4.63\n",
      "[20/50] [199/1027] mean_loss : 4.63\n",
      "[20/50] [299/1027] mean_loss : 4.64\n",
      "[20/50] [399/1027] mean_loss : 4.65\n",
      "[20/50] [499/1027] mean_loss : 4.65\n",
      "[20/50] [599/1027] mean_loss : 4.66\n",
      "[20/50] [699/1027] mean_loss : 4.67\n",
      "[20/50] [799/1027] mean_loss : 4.68\n",
      "[20/50] [899/1027] mean_loss : 4.69\n",
      "[20/50] [999/1027] mean_loss : 4.69\n",
      "Recall@20: 0.6776 Recall@10: 0.5742  Recall@5:0.4656\n",
      "MRR@20:0.3272 MRR@10:0.3200 MRR@5:0.3054\n",
      "best result: 0.6782899342803587\n",
      "==================================\n",
      "2020-09-14 14:40:14\n",
      "[21/50] [099/1027] mean_loss : 4.61\n",
      "[21/50] [199/1027] mean_loss : 4.61\n",
      "[21/50] [299/1027] mean_loss : 4.62\n",
      "[21/50] [399/1027] mean_loss : 4.63\n",
      "[21/50] [499/1027] mean_loss : 4.64\n",
      "[21/50] [599/1027] mean_loss : 4.65\n",
      "[21/50] [699/1027] mean_loss : 4.65\n",
      "[21/50] [799/1027] mean_loss : 4.66\n",
      "[21/50] [899/1027] mean_loss : 4.67\n",
      "[21/50] [999/1027] mean_loss : 4.68\n",
      "Recall@20: 0.6784 Recall@10: 0.5739  Recall@5:0.4656\n",
      "MRR@20:0.3270 MRR@10:0.3197 MRR@5:0.3052\n",
      "best result: 0.6783576864879514\n",
      "==================================\n",
      "2020-09-14 14:42:29\n",
      "[22/50] [099/1027] mean_loss : 4.60\n",
      "[22/50] [199/1027] mean_loss : 4.59\n",
      "[22/50] [299/1027] mean_loss : 4.60\n",
      "[22/50] [399/1027] mean_loss : 4.61\n",
      "[22/50] [499/1027] mean_loss : 4.62\n",
      "[22/50] [599/1027] mean_loss : 4.62\n",
      "[22/50] [699/1027] mean_loss : 4.64\n",
      "[22/50] [799/1027] mean_loss : 4.65\n",
      "[22/50] [899/1027] mean_loss : 4.65\n",
      "[22/50] [999/1027] mean_loss : 4.66\n",
      "Recall@20: 0.6798 Recall@10: 0.5756  Recall@5:0.4659\n",
      "MRR@20:0.3271 MRR@10:0.3199 MRR@5:0.3052\n",
      "best result: 0.6797578987782018\n",
      "==================================\n",
      "2020-09-14 14:44:45\n",
      "[23/50] [099/1027] mean_loss : 4.60\n",
      "[23/50] [199/1027] mean_loss : 4.58\n",
      "[23/50] [299/1027] mean_loss : 4.59\n",
      "[23/50] [399/1027] mean_loss : 4.60\n",
      "[23/50] [499/1027] mean_loss : 4.61\n",
      "[23/50] [599/1027] mean_loss : 4.61\n",
      "[23/50] [699/1027] mean_loss : 4.62\n",
      "[23/50] [799/1027] mean_loss : 4.63\n",
      "[23/50] [899/1027] mean_loss : 4.64\n",
      "[23/50] [999/1027] mean_loss : 4.65\n",
      "Recall@20: 0.6791 Recall@10: 0.5751  Recall@5:0.4656\n",
      "MRR@20:0.3252 MRR@10:0.3180 MRR@5:0.3033\n",
      "best result: 0.6797578987782018\n",
      "==================================\n",
      "2020-09-14 14:47:00\n",
      "[24/50] [099/1027] mean_loss : 4.58\n",
      "[24/50] [199/1027] mean_loss : 4.57\n",
      "[24/50] [299/1027] mean_loss : 4.57\n",
      "[24/50] [399/1027] mean_loss : 4.58\n",
      "[24/50] [499/1027] mean_loss : 4.59\n",
      "[24/50] [599/1027] mean_loss : 4.60\n",
      "[24/50] [699/1027] mean_loss : 4.61\n",
      "[24/50] [799/1027] mean_loss : 4.62\n",
      "[24/50] [899/1027] mean_loss : 4.62\n",
      "[24/50] [999/1027] mean_loss : 4.63\n",
      "Recall@20: 0.6798 Recall@10: 0.5763  Recall@5:0.4666\n",
      "MRR@20:0.3264 MRR@10:0.3192 MRR@5:0.3045\n",
      "best result: 0.6797804828473994\n",
      "==================================\n",
      "2020-09-14 14:49:15\n",
      "[25/50] [099/1027] mean_loss : 4.57\n",
      "[25/50] [199/1027] mean_loss : 4.56\n",
      "[25/50] [299/1027] mean_loss : 4.56\n",
      "[25/50] [399/1027] mean_loss : 4.57\n",
      "[25/50] [499/1027] mean_loss : 4.57\n",
      "[25/50] [599/1027] mean_loss : 4.58\n",
      "[25/50] [699/1027] mean_loss : 4.59\n",
      "[25/50] [799/1027] mean_loss : 4.60\n",
      "[25/50] [899/1027] mean_loss : 4.61\n",
      "[25/50] [999/1027] mean_loss : 4.62\n",
      "Recall@20: 0.6812 Recall@10: 0.5780  Recall@5:0.4684\n",
      "MRR@20:0.3264 MRR@10:0.3192 MRR@5:0.3045\n",
      "best result: 0.6812258632760451\n",
      "==================================\n",
      "2020-09-14 14:51:30\n",
      "[26/50] [099/1027] mean_loss : 4.54\n",
      "[26/50] [199/1027] mean_loss : 4.54\n",
      "[26/50] [299/1027] mean_loss : 4.55\n",
      "[26/50] [399/1027] mean_loss : 4.56\n",
      "[26/50] [499/1027] mean_loss : 4.57\n",
      "[26/50] [599/1027] mean_loss : 4.58\n",
      "[26/50] [699/1027] mean_loss : 4.58\n",
      "[26/50] [799/1027] mean_loss : 4.59\n",
      "[26/50] [899/1027] mean_loss : 4.60\n",
      "[26/50] [999/1027] mean_loss : 4.61\n",
      "Recall@20: 0.6815 Recall@10: 0.5777  Recall@5:0.4670\n",
      "MRR@20:0.3260 MRR@10:0.3187 MRR@5:0.3039\n",
      "best result: 0.6815194561756137\n",
      "==================================\n",
      "2020-09-14 14:53:46\n",
      "[27/50] [099/1027] mean_loss : 4.54\n",
      "[27/50] [199/1027] mean_loss : 4.53\n",
      "[27/50] [299/1027] mean_loss : 4.54\n",
      "[27/50] [399/1027] mean_loss : 4.55\n",
      "[27/50] [499/1027] mean_loss : 4.55\n",
      "[27/50] [599/1027] mean_loss : 4.56\n",
      "[27/50] [699/1027] mean_loss : 4.57\n",
      "[27/50] [799/1027] mean_loss : 4.58\n",
      "[27/50] [899/1027] mean_loss : 4.59\n",
      "[27/50] [999/1027] mean_loss : 4.60\n",
      "Recall@20: 0.6806 Recall@10: 0.5768  Recall@5:0.4671\n",
      "MRR@20:0.3255 MRR@10:0.3182 MRR@5:0.3036\n",
      "best result: 0.6815194561756137\n",
      "==================================\n",
      "2020-09-14 14:56:02\n",
      "[28/50] [099/1027] mean_loss : 4.52\n",
      "[28/50] [199/1027] mean_loss : 4.51\n",
      "[28/50] [299/1027] mean_loss : 4.52\n",
      "[28/50] [399/1027] mean_loss : 4.53\n",
      "[28/50] [499/1027] mean_loss : 4.54\n",
      "[28/50] [599/1027] mean_loss : 4.55\n",
      "[28/50] [699/1027] mean_loss : 4.56\n",
      "[28/50] [799/1027] mean_loss : 4.57\n",
      "[28/50] [899/1027] mean_loss : 4.58\n",
      "[28/50] [999/1027] mean_loss : 4.58\n",
      "Recall@20: 0.6818 Recall@10: 0.5785  Recall@5:0.4671\n",
      "MRR@20:0.3261 MRR@10:0.3189 MRR@5:0.3039\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 14:58:18\n",
      "[29/50] [099/1027] mean_loss : 4.52\n",
      "[29/50] [199/1027] mean_loss : 4.50\n",
      "[29/50] [299/1027] mean_loss : 4.51\n",
      "[29/50] [399/1027] mean_loss : 4.52\n",
      "[29/50] [499/1027] mean_loss : 4.53\n",
      "[29/50] [599/1027] mean_loss : 4.54\n",
      "[29/50] [699/1027] mean_loss : 4.55\n",
      "[29/50] [799/1027] mean_loss : 4.56\n",
      "[29/50] [899/1027] mean_loss : 4.57\n",
      "[29/50] [999/1027] mean_loss : 4.57\n",
      "Recall@20: 0.6810 Recall@10: 0.5771  Recall@5:0.4664\n",
      "MRR@20:0.3252 MRR@10:0.3179 MRR@5:0.3031\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:00:34\n",
      "[30/50] [099/1027] mean_loss : 4.49\n",
      "[30/50] [199/1027] mean_loss : 4.50\n",
      "[30/50] [299/1027] mean_loss : 4.50\n",
      "[30/50] [399/1027] mean_loss : 4.51\n",
      "[30/50] [499/1027] mean_loss : 4.52\n",
      "[30/50] [599/1027] mean_loss : 4.53\n",
      "[30/50] [699/1027] mean_loss : 4.54\n",
      "[30/50] [799/1027] mean_loss : 4.55\n",
      "[30/50] [899/1027] mean_loss : 4.56\n",
      "[30/50] [999/1027] mean_loss : 4.56\n",
      "Recall@20: 0.6806 Recall@10: 0.5777  Recall@5:0.4666\n",
      "MRR@20:0.3250 MRR@10:0.3178 MRR@5:0.3029\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:02:50\n",
      "[31/50] [099/1027] mean_loss : 4.48\n",
      "[31/50] [199/1027] mean_loss : 4.48\n",
      "[31/50] [299/1027] mean_loss : 4.50\n",
      "[31/50] [399/1027] mean_loss : 4.50\n",
      "[31/50] [499/1027] mean_loss : 4.51\n",
      "[31/50] [599/1027] mean_loss : 4.52\n",
      "[31/50] [699/1027] mean_loss : 4.53\n",
      "[31/50] [799/1027] mean_loss : 4.54\n",
      "[31/50] [899/1027] mean_loss : 4.55\n",
      "[31/50] [999/1027] mean_loss : 4.55\n",
      "Recall@20: 0.6812 Recall@10: 0.5769  Recall@5:0.4664\n",
      "MRR@20:0.3252 MRR@10:0.3179 MRR@5:0.3031\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:05:05\n",
      "[32/50] [099/1027] mean_loss : 4.49\n",
      "[32/50] [199/1027] mean_loss : 4.48\n",
      "[32/50] [299/1027] mean_loss : 4.49\n",
      "[32/50] [399/1027] mean_loss : 4.49\n",
      "[32/50] [499/1027] mean_loss : 4.50\n",
      "[32/50] [599/1027] mean_loss : 4.51\n",
      "[32/50] [699/1027] mean_loss : 4.52\n",
      "[32/50] [799/1027] mean_loss : 4.53\n",
      "[32/50] [899/1027] mean_loss : 4.54\n",
      "[32/50] [999/1027] mean_loss : 4.55\n",
      "Recall@20: 0.6795 Recall@10: 0.5765  Recall@5:0.4654\n",
      "MRR@20:0.3242 MRR@10:0.3169 MRR@5:0.3021\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:07:22\n",
      "[33/50] [099/1027] mean_loss : 4.47\n",
      "[33/50] [199/1027] mean_loss : 4.47\n",
      "[33/50] [299/1027] mean_loss : 4.47\n",
      "[33/50] [399/1027] mean_loss : 4.49\n",
      "[33/50] [499/1027] mean_loss : 4.50\n",
      "[33/50] [599/1027] mean_loss : 4.50\n",
      "[33/50] [699/1027] mean_loss : 4.51\n",
      "[33/50] [799/1027] mean_loss : 4.52\n",
      "[33/50] [899/1027] mean_loss : 4.53\n",
      "[33/50] [999/1027] mean_loss : 4.54\n",
      "Recall@20: 0.6797 Recall@10: 0.5769  Recall@5:0.4665\n",
      "MRR@20:0.3244 MRR@10:0.3172 MRR@5:0.3024\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:09:38\n",
      "[34/50] [099/1027] mean_loss : 4.46\n",
      "[34/50] [199/1027] mean_loss : 4.45\n",
      "[34/50] [299/1027] mean_loss : 4.46\n",
      "[34/50] [399/1027] mean_loss : 4.47\n",
      "[34/50] [499/1027] mean_loss : 4.48\n",
      "[34/50] [599/1027] mean_loss : 4.49\n",
      "[34/50] [699/1027] mean_loss : 4.50\n",
      "[34/50] [799/1027] mean_loss : 4.51\n",
      "[34/50] [899/1027] mean_loss : 4.52\n",
      "[34/50] [999/1027] mean_loss : 4.53\n",
      "Recall@20: 0.6803 Recall@10: 0.5779  Recall@5:0.4662\n",
      "MRR@20:0.3229 MRR@10:0.3158 MRR@5:0.3008\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:11:53\n",
      "[35/50] [099/1027] mean_loss : 4.45\n",
      "[35/50] [199/1027] mean_loss : 4.45\n",
      "[35/50] [299/1027] mean_loss : 4.46\n",
      "[35/50] [399/1027] mean_loss : 4.47\n",
      "[35/50] [499/1027] mean_loss : 4.48\n",
      "[35/50] [599/1027] mean_loss : 4.48\n",
      "[35/50] [699/1027] mean_loss : 4.50\n",
      "[35/50] [799/1027] mean_loss : 4.50\n",
      "[35/50] [899/1027] mean_loss : 4.51\n",
      "[35/50] [999/1027] mean_loss : 4.52\n",
      "Recall@20: 0.6809 Recall@10: 0.5764  Recall@5:0.4657\n",
      "MRR@20:0.3234 MRR@10:0.3161 MRR@5:0.3012\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:14:09\n",
      "[36/50] [099/1027] mean_loss : 4.45\n",
      "[36/50] [199/1027] mean_loss : 4.45\n",
      "[36/50] [299/1027] mean_loss : 4.45\n",
      "[36/50] [399/1027] mean_loss : 4.46\n",
      "[36/50] [499/1027] mean_loss : 4.47\n",
      "[36/50] [599/1027] mean_loss : 4.48\n",
      "[36/50] [699/1027] mean_loss : 4.49\n",
      "[36/50] [799/1027] mean_loss : 4.50\n",
      "[36/50] [899/1027] mean_loss : 4.51\n",
      "[36/50] [999/1027] mean_loss : 4.52\n",
      "Recall@20: 0.6803 Recall@10: 0.5754  Recall@5:0.4647\n",
      "MRR@20:0.3231 MRR@10:0.3158 MRR@5:0.3009\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:16:25\n",
      "[37/50] [099/1027] mean_loss : 4.44\n",
      "[37/50] [199/1027] mean_loss : 4.43\n",
      "[37/50] [299/1027] mean_loss : 4.44\n",
      "[37/50] [399/1027] mean_loss : 4.45\n",
      "[37/50] [499/1027] mean_loss : 4.46\n",
      "[37/50] [599/1027] mean_loss : 4.47\n",
      "[37/50] [699/1027] mean_loss : 4.48\n",
      "[37/50] [799/1027] mean_loss : 4.49\n",
      "[37/50] [899/1027] mean_loss : 4.50\n",
      "[37/50] [999/1027] mean_loss : 4.51\n",
      "Recall@20: 0.6803 Recall@10: 0.5766  Recall@5:0.4655\n",
      "MRR@20:0.3230 MRR@10:0.3158 MRR@5:0.3009\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:18:41\n",
      "[38/50] [099/1027] mean_loss : 4.45\n",
      "[38/50] [199/1027] mean_loss : 4.44\n",
      "[38/50] [299/1027] mean_loss : 4.44\n",
      "[38/50] [399/1027] mean_loss : 4.45\n",
      "[38/50] [499/1027] mean_loss : 4.46\n",
      "[38/50] [599/1027] mean_loss : 4.47\n",
      "[38/50] [699/1027] mean_loss : 4.48\n",
      "[38/50] [799/1027] mean_loss : 4.49\n",
      "[38/50] [899/1027] mean_loss : 4.50\n",
      "[38/50] [999/1027] mean_loss : 4.50\n",
      "Recall@20: 0.6799 Recall@10: 0.5749  Recall@5:0.4653\n",
      "MRR@20:0.3224 MRR@10:0.3151 MRR@5:0.3003\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:20:57\n",
      "[39/50] [099/1027] mean_loss : 4.40\n",
      "[39/50] [199/1027] mean_loss : 4.42\n",
      "[39/50] [299/1027] mean_loss : 4.43\n",
      "[39/50] [399/1027] mean_loss : 4.44\n",
      "[39/50] [499/1027] mean_loss : 4.45\n",
      "[39/50] [599/1027] mean_loss : 4.46\n",
      "[39/50] [699/1027] mean_loss : 4.47\n",
      "[39/50] [799/1027] mean_loss : 4.48\n",
      "[39/50] [899/1027] mean_loss : 4.49\n",
      "[39/50] [999/1027] mean_loss : 4.50\n",
      "Recall@20: 0.6811 Recall@10: 0.5772  Recall@5:0.4653\n",
      "MRR@20:0.3234 MRR@10:0.3161 MRR@5:0.3011\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:23:13\n",
      "[40/50] [099/1027] mean_loss : 4.41\n",
      "[40/50] [199/1027] mean_loss : 4.41\n",
      "[40/50] [299/1027] mean_loss : 4.42\n",
      "[40/50] [399/1027] mean_loss : 4.43\n",
      "[40/50] [499/1027] mean_loss : 4.44\n",
      "[40/50] [599/1027] mean_loss : 4.45\n",
      "[40/50] [699/1027] mean_loss : 4.46\n",
      "[40/50] [799/1027] mean_loss : 4.47\n",
      "[40/50] [899/1027] mean_loss : 4.48\n",
      "[40/50] [999/1027] mean_loss : 4.49\n",
      "Recall@20: 0.6793 Recall@10: 0.5763  Recall@5:0.4633\n",
      "MRR@20:0.3230 MRR@10:0.3158 MRR@5:0.3006\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:25:29\n",
      "[41/50] [099/1027] mean_loss : 4.41\n",
      "[41/50] [199/1027] mean_loss : 4.41\n",
      "[41/50] [299/1027] mean_loss : 4.42\n",
      "[41/50] [399/1027] mean_loss : 4.43\n",
      "[41/50] [499/1027] mean_loss : 4.44\n",
      "[41/50] [599/1027] mean_loss : 4.45\n",
      "[41/50] [699/1027] mean_loss : 4.46\n",
      "[41/50] [799/1027] mean_loss : 4.47\n",
      "[41/50] [899/1027] mean_loss : 4.48\n",
      "[41/50] [999/1027] mean_loss : 4.49\n",
      "Recall@20: 0.6797 Recall@10: 0.5778  Recall@5:0.4655\n",
      "MRR@20:0.3228 MRR@10:0.3157 MRR@5:0.3007\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:27:45\n",
      "[42/50] [099/1027] mean_loss : 4.42\n",
      "[42/50] [199/1027] mean_loss : 4.40\n",
      "[42/50] [299/1027] mean_loss : 4.41\n",
      "[42/50] [399/1027] mean_loss : 4.42\n",
      "[42/50] [499/1027] mean_loss : 4.43\n",
      "[42/50] [599/1027] mean_loss : 4.44\n",
      "[42/50] [699/1027] mean_loss : 4.45\n",
      "[42/50] [799/1027] mean_loss : 4.46\n",
      "[42/50] [899/1027] mean_loss : 4.47\n",
      "[42/50] [999/1027] mean_loss : 4.48\n",
      "Recall@20: 0.6787 Recall@10: 0.5772  Recall@5:0.4646\n",
      "MRR@20:0.3210 MRR@10:0.3139 MRR@5:0.2988\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:30:01\n",
      "[43/50] [099/1027] mean_loss : 4.41\n",
      "[43/50] [199/1027] mean_loss : 4.40\n",
      "[43/50] [299/1027] mean_loss : 4.41\n",
      "[43/50] [399/1027] mean_loss : 4.42\n",
      "[43/50] [499/1027] mean_loss : 4.43\n",
      "[43/50] [599/1027] mean_loss : 4.44\n",
      "[43/50] [699/1027] mean_loss : 4.45\n",
      "[43/50] [799/1027] mean_loss : 4.46\n",
      "[43/50] [899/1027] mean_loss : 4.47\n",
      "[43/50] [999/1027] mean_loss : 4.48\n",
      "Recall@20: 0.6783 Recall@10: 0.5750  Recall@5:0.4624\n",
      "MRR@20:0.3208 MRR@10:0.3136 MRR@5:0.2985\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:32:16\n",
      "[44/50] [099/1027] mean_loss : 4.40\n",
      "[44/50] [199/1027] mean_loss : 4.39\n",
      "[44/50] [299/1027] mean_loss : 4.40\n",
      "[44/50] [399/1027] mean_loss : 4.41\n",
      "[44/50] [499/1027] mean_loss : 4.43\n",
      "[44/50] [599/1027] mean_loss : 4.43\n",
      "[44/50] [699/1027] mean_loss : 4.44\n",
      "[44/50] [799/1027] mean_loss : 4.45\n",
      "[44/50] [899/1027] mean_loss : 4.46\n",
      "[44/50] [999/1027] mean_loss : 4.47\n",
      "Recall@20: 0.6778 Recall@10: 0.5759  Recall@5:0.4651\n",
      "MRR@20:0.3215 MRR@10:0.3144 MRR@5:0.2995\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:34:32\n",
      "[45/50] [099/1027] mean_loss : 4.40\n",
      "[45/50] [199/1027] mean_loss : 4.39\n",
      "[45/50] [299/1027] mean_loss : 4.40\n",
      "[45/50] [399/1027] mean_loss : 4.41\n",
      "[45/50] [499/1027] mean_loss : 4.42\n",
      "[45/50] [599/1027] mean_loss : 4.43\n",
      "[45/50] [699/1027] mean_loss : 4.44\n",
      "[45/50] [799/1027] mean_loss : 4.45\n",
      "[45/50] [899/1027] mean_loss : 4.45\n",
      "[45/50] [999/1027] mean_loss : 4.46\n",
      "Recall@20: 0.6780 Recall@10: 0.5743  Recall@5:0.4630\n",
      "MRR@20:0.3212 MRR@10:0.3139 MRR@5:0.2990\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:36:48\n",
      "[46/50] [099/1027] mean_loss : 4.39\n",
      "[46/50] [199/1027] mean_loss : 4.39\n",
      "[46/50] [299/1027] mean_loss : 4.39\n",
      "[46/50] [399/1027] mean_loss : 4.41\n",
      "[46/50] [499/1027] mean_loss : 4.41\n",
      "[46/50] [599/1027] mean_loss : 4.42\n",
      "[46/50] [699/1027] mean_loss : 4.43\n",
      "[46/50] [799/1027] mean_loss : 4.44\n",
      "[46/50] [899/1027] mean_loss : 4.45\n",
      "[46/50] [999/1027] mean_loss : 4.46\n",
      "Recall@20: 0.6776 Recall@10: 0.5734  Recall@5:0.4641\n",
      "MRR@20:0.3208 MRR@10:0.3135 MRR@5:0.2988\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:39:04\n",
      "[47/50] [099/1027] mean_loss : 4.40\n",
      "[47/50] [199/1027] mean_loss : 4.39\n",
      "[47/50] [299/1027] mean_loss : 4.40\n",
      "[47/50] [399/1027] mean_loss : 4.40\n",
      "[47/50] [499/1027] mean_loss : 4.41\n",
      "[47/50] [599/1027] mean_loss : 4.42\n",
      "[47/50] [699/1027] mean_loss : 4.43\n",
      "[47/50] [799/1027] mean_loss : 4.44\n",
      "[47/50] [899/1027] mean_loss : 4.44\n",
      "[47/50] [999/1027] mean_loss : 4.45\n",
      "Recall@20: 0.6779 Recall@10: 0.5747  Recall@5:0.4641\n",
      "MRR@20:0.3200 MRR@10:0.3128 MRR@5:0.2980\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:41:19\n",
      "[48/50] [099/1027] mean_loss : 4.37\n",
      "[48/50] [199/1027] mean_loss : 4.37\n",
      "[48/50] [299/1027] mean_loss : 4.38\n",
      "[48/50] [399/1027] mean_loss : 4.38\n",
      "[48/50] [499/1027] mean_loss : 4.40\n",
      "[48/50] [599/1027] mean_loss : 4.41\n",
      "[48/50] [699/1027] mean_loss : 4.42\n",
      "[48/50] [799/1027] mean_loss : 4.43\n",
      "[48/50] [899/1027] mean_loss : 4.44\n",
      "[48/50] [999/1027] mean_loss : 4.45\n",
      "Recall@20: 0.6767 Recall@10: 0.5747  Recall@5:0.4628\n",
      "MRR@20:0.3191 MRR@10:0.3120 MRR@5:0.2970\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "2020-09-14 15:43:34\n",
      "[49/50] [099/1027] mean_loss : 4.37\n",
      "[49/50] [199/1027] mean_loss : 4.37\n",
      "[49/50] [299/1027] mean_loss : 4.37\n",
      "[49/50] [399/1027] mean_loss : 4.38\n",
      "[49/50] [499/1027] mean_loss : 4.39\n",
      "[49/50] [599/1027] mean_loss : 4.41\n",
      "[49/50] [699/1027] mean_loss : 4.42\n",
      "[49/50] [799/1027] mean_loss : 4.43\n",
      "[49/50] [899/1027] mean_loss : 4.43\n",
      "[49/50] [999/1027] mean_loss : 4.45\n",
      "Recall@20: 0.6772 Recall@10: 0.5729  Recall@5:0.4620\n",
      "MRR@20:0.3187 MRR@10:0.3113 MRR@5:0.2965\n",
      "best result: 0.6817678809367872\n",
      "==================================\n",
      "[[0.46710630321371305, 0.5785361006346124, 0.6817678809367872, tensor(0.3039), tensor(0.3189), tensor(0.3261, device='cuda:0')]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "w_list = [20]\n",
    "record = list()\n",
    "for w in w_list:\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    train_sets = TensorDataset(train_x.long(), train_pos.long(), train_y.long())\n",
    "    train_dataload = DataLoader(train_sets, batch_size=512, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    test_x, test_pos, test_y = test_x.long(), test_pos.long(), test_y.long()\n",
    "    all_test_sets = TensorDataset(test_x, test_pos, test_y)\n",
    "    test_dataload = DataLoader(all_test_sets, batch_size=512,shuffle=False)\n",
    "    model = DualAttention(100, 100, 40842, 71, w, dropout=0.5, activate='relu').cuda()\n",
    "    opti = optim.Adam(model.parameters(), lr=0.001, weight_decay=0, amsgrad=True)\n",
    "    best_result = 0\n",
    "    total_time = 0\n",
    "    best_result_5 = 0\n",
    "    best_result_ = []\n",
    "    for epoch in range(50):\n",
    "        start_time = datetime.datetime.now()\n",
    "        print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        losses = 0\n",
    "        for step, (x_train, pos_train, y_train) in enumerate(train_dataload):\n",
    "            opti.zero_grad()\n",
    "            q = model(x_train.cuda(), pos_train.cuda())\n",
    "            loss = criterion(q, y_train.cuda()-1)\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            losses += loss.item()\n",
    "            if (step + 1) % 100 == 0:\n",
    "                print(\"[%02d/%d] [%03d/%d] mean_loss : %0.2f\" % (epoch, 50, step, len(train_sets) / 512, losses / step + 1))\n",
    "        end_time = datetime.datetime.now()\n",
    "        with torch.no_grad():\n",
    "            y_pre_all = torch.LongTensor().cuda()\n",
    "            y_pre_all_10 = torch.LongTensor()\n",
    "            y_pre_all_5 = torch.LongTensor()\n",
    "            for x_test, pos_test, y_test in test_dataload:\n",
    "                with torch.no_grad():\n",
    "                    y_pre = model.predict(x_test.cuda(), pos_test.cuda(), 20)\n",
    "                    y_pre_all = torch.cat((y_pre_all, y_pre), 0)\n",
    "                    y_pre_all_10 = torch.cat((y_pre_all_10, y_pre.cpu()[:, :10]), 0)\n",
    "                    y_pre_all_5 = torch.cat((y_pre_all_5, y_pre.cpu()[:, :5]), 0)\n",
    "            recall = get_recall(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "            recall_10 = get_recall(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "            recall_5 = get_recall(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "            mrr = get_mrr(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "            mrr_10 = get_mrr(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "            mrr_5 = get_mrr(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "    \n",
    "            print(\"Recall@20: \" + \"%.4f\" %recall + \" Recall@10: \" + \"%.4f\" %recall_10 +\"  Recall@5:\" + \"%.4f\" %recall_5)\n",
    "            print(\"MRR@20:\" + \"%.4f\" % mrr.tolist() + \" MRR@10:\" + \"%.4f\" % mrr_10.tolist() + \" MRR@5:\" + \"%.4f\" % mrr_5.tolist())\n",
    "            if best_result < recall:\n",
    "                best_result = recall\n",
    "                best_result_ = [recall_5, recall_10, recall, mrr_5, mrr_10, mrr]\n",
    "                # torch.save(model.state_dict(), 'BestModel/best_dn_w_%s.pth' % str(w))\n",
    "            print(\"best result: \" + str(best_result))\n",
    "            print(\"==================================\")\n",
    "    record.append(best_result_)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "model = DualAttention(100, 100, 40842, 71, 20, atten_way='MLP', decoder_way='trilinear2', dropout=0.5, activate='relu').cuda()\n",
    "model.load_state_dict(torch.load('BestModel/best_dn_w_20.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Recall@20: 0.6821 Recall@10: 0.5773  Recall@5:0.4665\n",
      "MRR@20:0.3246 MRR@10:0.3173 MRR@5:0.3024\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pre_all = torch.LongTensor().cuda()\n",
    "    y_pre_all_10 = torch.LongTensor()\n",
    "    y_pre_all_5 = torch.LongTensor()\n",
    "    for x_test, pos_test, y_test in test_dataload:\n",
    "        with torch.no_grad():\n",
    "            y_pre = model.predict(x_test.cuda(), pos_test.cuda(), 20)\n",
    "            y_pre_all = torch.cat((y_pre_all, y_pre), 0)\n",
    "            y_pre_all_10 = torch.cat((y_pre_all_10, y_pre.cpu()[:, :10]), 0)\n",
    "            y_pre_all_5 = torch.cat((y_pre_all_5, y_pre.cpu()[:, :5]), 0)\n",
    "    recall = get_recall(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "    recall_10 = get_recall(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "    recall_5 = get_recall(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "    mrr = get_mrr(y_pre_all, test_y.cuda().unsqueeze(1)-1)\n",
    "    mrr_10 = get_mrr(y_pre_all_10, test_y.unsqueeze(1)-1)\n",
    "    mrr_5 = get_mrr(y_pre_all_5, test_y.unsqueeze(1)-1)\n",
    "\n",
    "    print(\"Recall@20: \" + \"%.4f\" %recall + \" Recall@10: \" + \"%.4f\" %recall_10 +\"  Recall@5:\" + \"%.4f\" %recall_5)\n",
    "    print(\"MRR@20:\" + \"%.4f\" % mrr.tolist() + \" MRR@10:\" + \"%.4f\" % mrr_10.tolist() + \" MRR@5:\" + \"%.4f\" % mrr_5.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "yjh",
   "language": "python",
   "display_name": "yjh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}